---
## ðŸ§  Extending Spider2â€‘V: A Fully Pythonic, Modular & Futureâ€‘Proof Benchmarking Framework

We present an extension of the Spider2â€‘V benchmark redesigned for **full Python compatibility**, enabling fast iteration, rich agentâ€“environment interaction, and seamless integration with modern ML infrastructure.
---

### 1. **Sandboxed VMs via Pythonâ€‘Driven QEMU + Docker Orchestration**

- At the core is a lightweight Python wrapper over `docker` + QEMU, managing **parallel VMs** spun up inside Docker containers.
- Each VM is isolated, yet controllable via SSH and container-shared mounts.
- VM lifecycle, snapshotting, and network I/O are fully scriptable via Python.
- Configurable in one line â€” swap OS images or VM templates by simply changing a field in `SandboxVMConfig`.

âž¡ï¸ **Result**: Fast parallel benchmarks, reproducible environments, and no manual hypervisor tools required.

![Agent-OS OVerview](../media/overview-framework.png)

---

### 2. **Inâ€‘VM Services via FastAPI + Jupyter Kernel Gateway**

Inside each guest VM, the benchmark framework runs two cooperating services:

- **FastAPI sandbox server**:

  - Exposes VM-level capabilities like screenshots, GUI event recording (via `pyautogui` + `Xcursor`), file management, and action replay.
  - Fully OpenAPI-compliant with a dynamic client generated by `openapi-python-client`.
  - Enables typed, traceable communication from the orchestrator to in-VM services.

- **Jupyter Kernel Gateway**:
  - Runs Python code inside the VM kernel via WebSockets.
  - Supports `%pip`, `!uv pip install`, dynamic imports â€” everything an interactive LLM agent needs.
  - Based on the official `uv` kernel setup, with named kernel support and isolation via `uv venv --seed`.

âž¡ï¸ **Result**: Your agent gets interactive Python + API access inside a full VM â€” enabling real browser/UI tasks, not just mocks.

---

### 3. **Modular Agents via `smolagents`**

- Agents are built using [`smolagents`](https://github.com/smol-ai/smolagents) â€” a minimal, composable Python framework.
- Tool-based design: Each capability (e.g., execute, take screenshot, search file system) is just a Python function wrapped in a `Tool`.
- Pluggable `Executor` and `LLMAdapter` backends let you test OpenAI, local HF models (e.g. vLLM, Qwen), or sandbox-executed Python.

âž¡ï¸ **Result**: Agents can execute code _inside_ the VM, trigger actions, observe outputs, and reflect â€” all through typed Python tools.

![Agent Inference Providers](../media/ai-platforms-and-providers.png)
![Agent Workflow](../media/overview-workflow.png)
![Agent Tools](../media/overview-tools.png)

---

### ðŸ” Why It Matters

- **Agent Realism**: They donâ€™t just hallucinate â€” they click, type, install, screenshot, and _run_ code in real VMs.
- **Deterministic CI**: Using `uv` means repeatable Python environments with lockfileâ€‘based execution.
- **Highly Modular**: Swap just the FastAPI interface, the LLM backend, or a tool class â€” nothing breaks.
- **Scaleâ€‘ready**: Each agent has its own isolated OS to play in. Bench 5, 50, or 500 agents with a single orchestrator call.

---

### ðŸš€ Easy Extension & Baseline Improvement

Because the benchmark is **100% Python**:

- ðŸ§ª Add new tools by writing Python functions.
- ðŸ§© Compose new agent behaviors using standard function chaining.
- ðŸ§  Run **ablation studies**, **reflective reasoning**, or **debugging agents** with just Python.
- ðŸ§¬ Autoâ€‘generate reproducible runs with no lockfile drift (`uv` handles envs).
- ðŸ“¦ Package the sandbox server as a versioned PyPI package â€” coming soon!

---

### ðŸ’¡ Example Flow

```text
AgentOrchestrator
â”‚
â”œâ”€â”€â–¶ Spins up N VMs in Docker
â”‚     â”œâ”€â”€ Installs FastAPI + Jupyter Gateway inside each VM
â”‚     â””â”€â”€ Starts kernel + logs services
â”‚
â”œâ”€â”€â–¶ AgentVMManager
â”‚     â””â”€â”€ Generates Python client from OpenAPI + binds methods
â”‚
â”œâ”€â”€â–¶ Agent (via smolagents)
â”‚     â””â”€â”€ Calls tools â†’ API requests â†’ Sandbox executes
â”‚
â””â”€â”€â–¶ Results saved, screenshots logged, VM auto-destroyed or snapshotted
```

---

## âœ… Summary

> This re-architecture makes **Spider2â€‘V agent benchmarking scalable, modular, and futureâ€‘proof.**
> All in Python. All reproducible. All ready for real-world LLM agents.
