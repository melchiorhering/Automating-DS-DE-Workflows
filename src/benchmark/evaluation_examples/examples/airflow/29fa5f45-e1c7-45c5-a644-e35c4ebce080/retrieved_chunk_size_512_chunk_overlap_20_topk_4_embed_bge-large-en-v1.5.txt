Documentation Source:
docs.astronomer.io/astro/cli/troubleshoot-locally.txt

Documentation Title:
Troubleshoot a local Airflow environment | Astronomer Documentation

Documentation Content:
Run
docker stop $(docker ps -q)
to stop all running Docker containers.
Change the default port assignment
​
If port 8080 or 5432 are in use on your machine by other services, the Airflow webserver and metadata database won't be able to start. To run these components on different ports, run the following commands in your Astro project:
astro config
set
webserver.port
<
available-port
>
astro config
set
postgres.port
<
available-port
>
For example, to use 8081 for your webserver port and 5435 for your database port, you would run the following commands:
astro config
set
webserver.port
8081
astro config
set
postgres.port
5435
Was this page helpful?
Yes
No
Sign up for Developer Updates
Get a summary of new Astro features once a month.
Submit
You can unsubscribe at any time.
By proceeding you agree to our
Privacy Policy
, our
Website Terms
and to receive emails from Astronomer.
Edit this page
Previous
Use Airflow connections from Astro
Next
Test your DAGs
Troubleshoot KubernetesPodOperator issues
Troubleshoot dependency errors
New DAGs aren't visible in the Airflow UI
DAGs running slowly
Astro project won't load after running
astro dev start
Ports are not available for my local Airflow webserver
Stop all running Docker containers
Change the default port assignment
Legal
·
Privacy
·
Security
·
Cookie Preferences
© Astronomer 2023. Various trademarks held by their respective owners.



Documentation Source:
docs.astronomer.io/astro/cli/get-started-cli.txt

Documentation Title:
Get started with Airflow using the Astro CLI | Astronomer Documentation

Documentation Content:
To start running your project in a local Airflow environment, run the following command from your project directory:
astro dev start
This command builds your project and spins up 4 Docker containers on your machine, each for a different Airflow component:
Postgres:
Airflow's metadata database
Webserver:
The Airflow component responsible for rendering the Airflow UI
Scheduler:
The Airflow component responsible for monitoring and triggering tasks
Triggerer:
The Airflow component responsible for running Triggers and signaling tasks to resume when their conditions have been met. The triggerer is used exclusively for tasks that are run with
deferrable operators
After your project builds successfully, open the Airflow UI in your web browser at
https://localhost:8080/
.
Find your DAGs in the
dags
directory in the Airflow UI.
In this directory, you can find several example DAGs including
example-dag-basic
DAG, which was generated with your Astro project. To provide a basic demonstration of an ETL pipeline, this DAG creates an example JSON string, calculates a value based on the string, and prints the results of the calculation to the Airflow logs.
info
The Astro CLI uses port
8080
for the Airflow webserver and port
5432
for the Airflow metadata database by default. If these ports are already in use on your local computer, an error message might appear. To resolve this error message, see
Run Airflow locally
.
Step 3: Develop locally with the CLI
​
Now that you have a locally running project, you can start to develop your Astro project by adding DAGs, dependencies, environment variables, and more. See
Develop your project
for more details on how to modify all aspects of your Astro project.
Most changes you make, including updates to your DAG code, are applied automatically to your running environment and don't require rebuilding your project. However, you must rebuild your project and restart your environment to apply changes from any of the following files in your Astro project:
packages.txt
Dockerfile
requirements.txt
airflow_settings.yaml
To restart your local Airflow environment, run:
astro dev restart
This command rebuilds your image and restarts the Docker containers running on your local machine with the new image.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow.txt

Documentation Title:
Get started with Apache Airflow, Part 1: Write and run your first DAG | Astronomer Documentation

Documentation Content:
(Optional) A local installation of
Python 3
to improve your Python developer experience.
Step 1: Create an Astro project
​
To run data pipelines on Astro, you first need to create an Astro project, which contains the set of files necessary to run Airflow locally. This can be done with the
Astro CLI
.
Create a new directory for your Astro project:
mkdir
<
your-astro-project-name
>
Open the directory:
cd
<
your-astro-project-name
>
Run the following Astro CLI command to initialize an Astro project in the directory:
astro dev init
The Astro project is built to run Airflow with Docker.
Docker
is a service to run software in virtualized containers within a machine. When you run Airflow on your machine with the Astro CLI, Docker creates a container for each Airflow component that is required to run DAGs. For this tutorial, you don't need an in-depth knowledge of Docker. All you need to know is that Airflow runs on the compute resources of your machine, and that all necessary files for running Airflow are included in your Astro project.
The default Astro project structure includes a collection of folders and files that you can use to run and customize Airflow. For this tutorial, you only need to know the following files and folders:
/dags
: A directory of DAG files. Each Astro project includes an example DAG called
example_astronauts
. For more information on DAGs, see
Introduction to Airflow DAGs
.
Dockerfile
: This is where you specify your version of
Astro Runtime
, which is a runtime software based on Apache Airflow that is built and maintained by Astronomer. The CLI generates new Astro projects with the latest version of Runtime, which is equivalent to the latest version of Airflow. For advanced use cases, you can also configure this file with Docker-based commands to run locally at build time.
Step 2: Start Airflow
​
Now that you have an Astro project ready, the next step is to actually start Airflow on your machine.



Documentation Source:
docs.astronomer.io/astro/cli/get-started-cli.txt

Documentation Title:
Get started with Airflow using the Astro CLI | Astronomer Documentation

Documentation Content:
Get started with Airflow using the Astro CLI | Astronomer Documentation
Skip to main content
Docs
Docs
Find what you're looking for
Learn About Astronomer
Get Started Free
Home
Astro
Astro CLI
Software
Learn
Try Astro
Overview
Install the CLI
Quickstart
Develop your project
Run Airflow locally
Test your DAGs
Release notes
Release and lifecycle policy
Advanced
Command reference
Support Knowledge Base
Office Hours
Webinars
Astro Status
Quickstart
On this page
Get started with Airflow using the Astro CLI
One of the Astro CLI's main features is its ability to run Airflow on your local machine. After you install the Astro CLI and Docker Desktop, follow this quickstart to build an Airflow project and run it in a local Airflow environment using just a few commands. At the end of the tutorial, you'll have all of the files and components you need to develop and test Airflow DAGs locally.
Prerequisites
​
The
Astro CLI
Docker Desktop
(v18.09 or higher).
Step 1: Create an Astro project
​
An
Astro project
contains the set of files necessary to run Airflow, including dedicated folders for your DAG files, plugins, and dependencies. All new Astro projects contain two example DAGs. This set of files builds a Docker image that you can both run on your local machine with Airflow and deploy to Astro.
astro dev init
This command generates all of the project files you need to run Airflow locally, including example DAGs that you can run out of the box. See
Create an Astro project
for more information about the default project structure.
Step 2: Run Airflow locally
​
Running your project locally allows you to test your DAGs before you deploy them to a production environment. While this step is not required for deploying and running your code on Astro, Astronomer recommends always using the Astro CLI to test locally before deploying.



