Documentation Source:
docs.astronomer.io/astro/airflow-api.html

Documentation Title:
Make requests to the Airflow REST API | Astronomer Documentation

Documentation Content:
This is sometimes necessary when you have interdependent workflows across multiple Deployments. On Astro, you can do this for any Deployment in any Workspace or cluster.</p><p>This topic has guidelines on how to trigger a DAG run, but you can modify the example DAG provided to trigger any request that's supported in the Airflow REST API.</p><ol><p>Create a <a>Deployment API token</a>for the Deployment that contains the DAG you want to trigger.</p><li><p>In the Deployment that contains the triggering DAG, create an <a>Airflow HTTP connection</a>with the following values:</p><ul><li><strong>Connection Id</strong>: <code>http_conn</code></li><li><strong>Connection Type</strong>: HTTP</li><li><strong>Host</strong>: <code>&lt;your-deployment-url&gt;</code></li><li><strong>Schema</strong>: <code>https</code></li><li><strong>Extras</strong>:</li></ul><code><span>{</span><span><span>"Content-Type"</span><span>:</span><span>"application/json"</span><span>,</span></span><span><span>"Authorization"</span><span>:</span><span>"Bearer &lt;your-deployment-api-token&gt;"</span></span><span>}</span></code><p>See <a>Manage connections in Apache Airflow</a>.</p></li></ol><div><div>info</div><p>If the <code>HTTP</code>connection type is not available, double check that the <a>HTTP provider</a>is installed in your Airflow environment. If it's not, add <code>apache-airflow-providers-http</code>to the <code>requirements.txt</code>file of our Astro project and redeploy it to Astro.</p></div><li><p>In your triggering DAG, add the following task. It uses the <a>SimpleHttpOperator</a>to make a request to the <code>dagRuns</code>endpoint of the Deployment that contains the DAG to trigger.



Documentation Source:
docs.astronomer.io/astro/airflow-api.html

Documentation Title:
Make requests to the Airflow REST API | Astronomer Documentation

Documentation Content:
For example, you can externally trigger a DAG run without accessing your Deployment directly by making an HTTP request in Python or cURL to the <a>dagRuns endpoint</a>in the Airflow REST API.</p><p>To test Airflow API calls in a local Airflow environment running with the Astro CLI, see <a>Troubleshoot your local Airflow environment</a>.</p><div><div>info</div><p>Updates to the Airflow REST API are released in new Airflow versions and new releases don’t have a separate release cycle or versioning scheme. To take advantage of specific Airflow REST API functionality, you might need to upgrade Astro Runtime. See <a>Upgrade Runtime</a>and the <a>Airflow release notes</a>.</p></div><h2>Prerequisites<a>​</a></h2><ul><li>A Deployment on Astro.</li><li>A <a>Deployment API token</a>, <a>Workspace API token</a>, or an <a>Organization API token</a>.</li><li><a>cURL</a>or, if using Python, the <a>Requests library</a>.</li><li>The <a>Astro CLI</a>.</li></ul><h2>Step 1: Retrieve your access token<a>​</a></h2><div><ul><li>Workspace token</li><li>Organization token</li><li>Deployment API token</li></ul><div><p>Follow the steps in <a>Create a Workspace API token</a>to create your token. Make sure to save the token on creation in order to use it later in this setup.</p><p>Follow the steps in <a>Create a Orgaization API token</a>to create your token. Make sure to save the token on creation in order to use it later in this setup.</p><p>Follow the steps in <a>Create a Deployment API token</a>to create your token.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow-part-2.html

Documentation Title:
Get started with Apache Airflow, Part 2: Providers, connections, and variables | Astronomer Documentation

Documentation Content:
If you need to create a token, you can follow the <a>official GitHub documentation</a>.</li><li>Save the connection by clicking the <strong>Save</strong>button.</li></ol><p>Note that the option to test connections is only available for selected connection types and disabled by default in Airflow 2.7+, see <a>Test a connection</a>.</p><h2>Step 5: Create an HTTP connection<a>​</a></h2><ol><li>In the <strong>Connections</strong>view, click <strong>+</strong>to create a new connection.</li><li>Name the connection <code>open_notify_api_conn</code>and select a <strong>Connection Type</strong>of <code>HTTP</code>.</li><li>Enter the host URL for the API you want to query in the <strong>Host</strong>field. For this tutorial we use the <a>Open Notify API</a>, which has an endpoint returning the current location of the ISS. The host for this API is <code>http://api.open-notify.org</code>.</li><li>Click <strong>Save</strong>.</li></ol><p>You should now have two connections as shown in the following screenshot:</p><h2>Step 6: Review the DAG code<a>​</a></h2><p>Now that your Airflow environment is configured correctly, look at the DAG code you copied from the repository to see how your new variable and connections are used at the code level.</p><p>At the top of the file, the DAG is described in a docstring.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow-part-2.html

Documentation Title:
Get started with Apache Airflow, Part 2: Providers, connections, and variables | Astronomer Documentation

Documentation Content:
It's highly recommended to always document your DAGs and include any additional connections or variables that are required for the DAG to work.</p><code><span>"""</span><span>## Find the International Space Station</span><span>This DAG waits for a specific commit message to appear in a GitHub repository, </span><span>and then pulls the current location of the International Space Station from an API</span><span>and print it to the logs.</span><span>This DAG needs a GitHub connection with the name `my_github_conn` and </span><span>an HTTP connection with the name `open_notify_api_conn`</span><span>and the host `https://api.open-notify.org/` to work.</span><span>Additionally you need to set an Airflow variable with </span><span>the name `open_notify_api_endpoint` and the value `iss-now.json`.</span><span>"""</span></code><p>After the docstring, all necessary packages are imported.



