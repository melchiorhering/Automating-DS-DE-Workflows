Documentation Source:
airbyte.com/tutorials/incremental-change-data-capture-cdc-replication.txt

Documentation Title:
Airbyte's incremental Change Data Capture (CDC) replication | Airbyte

Documentation Content:
Then select
Postgres
as the source as follows:
Define a source connector called
cdc-source
as follows, and be sure to select
Logical Replication (CDC)
as demonstrated below”:
After selecting Logical Replication (CDC), enter the parameters that will be used for CDC replication as shown below.
Then click on the
Set up source
button to create the source connector,
Instantiate a Postgres destination connector
Select Postgres as the destination as follows:
Create a destination called
cdc-destination
as follows:
And click on the
Set up destination
button to create the destination connector.
Set up the CDC connection with incremental dedupe synchronization
The orchestration for CDC syncing is similar to non-CDC database sources – in other words, CDC replication works in conjunction with the
various Sync modes
that Airbyte supports. In this tutorial I will demonstrate CDC replication only with the incremental dedupe synchronization mode.
ℹ️ The steps presented in this section could also be used for testing other sync modes.
Define a new connection that will be used for incremental CDC replication as follows:
ℹ️  In the definition of a CDC replication connection, notice that a
cursor field
is not required (as opposed to “standard”
incremental replication
). Furthermore, the
primary key
is automatically determined from the source table, and is therefore not selected.
Once you click on
Set up connection
, Airbyte will start a sync operation from the source to the destination. Once the sync has completed, you should see  a response similar to the following:
‍
View the destination database
Open a Postgres shell to the destination as follows:
docker exec -it airbyte-destination psql --username=postgres
You can then view the names of the tables in the destination with the following command:
\dt;
Which should respond with the following.



Documentation Source:
airbyte.com/tutorials/postgresql-change-data-capture-elt.txt

Documentation Title:
Build an EL(T) from Postgres CDC (Change Data Capture) | Airbyte

Documentation Content:
We advise users to add only the tables that they want to sync in the publication and not all tables.
CREATE PUBLICATION pub1 FOR TABLE cars;
Should you build or buy your data pipelines?
Download our free guide and discover the best approach for your needs, whether it's building your ELT solution in-house or opting for Airbyte Open Source or Airbyte Cloud.
Download now
Step 3: Configure a PostgreSQL source in Airbyte
To set up a new PostgreSQL Airbyte source, go to
Airbyte's UI
, click on sources and add a new source.
As the connector type, select
Postgres
. As demonstrated in the subsequent illustrations, fill in the following configuration fields if you used the instructions above to configure your Postgres database.
Name:
Postgres CDC Tutorial (or any name you'd like)
Host:
localhost
Port:
5432
DB Name:
postgres
Schemas:
postgres
User:
airbyte
Password:
password (or any password you assigned to the airbyte user)
Connect using SSL:
disabled
Replication method:
Logical replication (CDC)
Plugin:
pgoutput
Replication_slot:
airbyte_slot
Publication:
pub1
SSH Tunnel Method:
No Tunnel
Then click on
Set up source
and Airbyte will test the connection. If everything goes well, you should see a successful message.
Step 4: Configure a local JSON destination in Airbyte
Go to destinations and add a new one. As demonstrated in the following diagram, select
Local JSON
as the destination type and fill in with the following details.
Name:
JSON CDC Tutorial (or any name you would like)
Destination_path:
/cdc_tutorial (or any path where you'd like to store the Postgres data)
‍
Then click on
Set up source
and let Airbyte test the destination.
Step 5: Create an Airbyte connection
Go to connections and create a new connection. Then, select the existing Postgres source you have just created and then do the same for the Local JSON destination. Once you're done, you can set up the connection as follows.
Replication Frequency:
I recommend setting it to "manual" if you're testing. You can change to any frequency that makes sense to your use case when you're ready.



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/sources/postgres/postgres-troubleshooting.txt

Documentation Title:
Troubleshooting Postgres Sources | Airbyte Documentation

Documentation Content:
Depending on the destination connected to this source, however, the schema may be altered. See the destination's documentation for more details.
The following two schema evolution actions are currently supported:
Adding/removing tables without resetting the entire connection at the destination
Caveat: In the CDC mode, adding a new table to a connection may become a temporary bottleneck. When a new table is added, the next sync job takes a full snapshot of the new table before it proceeds to handle any changes.
Resetting a single table within the connection without resetting the rest of the destination tables in that connection
Changing a column data type or removing a column might break connections.
Version Requirements
​
For Airbyte Open Source users,
upgrade
your Airbyte platform to version
v0.58.0
or newer
Use Postgres v9.3.x or above for non-CDC workflows and Postgres v10 or above for CDC workflows
For Airbyte Cloud (and optionally for Airbyte Open Source), ensure SSL is enabled in your environment
CDC Requirements
​
Incremental sync is only supported for tables with primary keys. For tables without primary keys, use
Full Refresh sync
.
Data must be in tables and not views. If you require data synchronization from a view, you would need to create a new connection with
Standard
as
Replication Method
.
The modifications you want to capture must be made using
DELETE
/
INSERT
/
UPDATE
. For example, changes made using
TRUNCATE
/
ALTER
will not appear in logs and therefore in your destination.
Schema changes are not supported automatically for CDC sources. Reset and resync data if you make a schema change.
The records produced by
DELETE
statements only contain primary keys. All other data fields are unset.
Log-based replication only works for master instances of Postgres. CDC cannot be run from a read-replica of your primary database.
An Airbyte database source using CDC replication can only be used with a single Airbyte destination. This is due to how Postgres CDC is implemented - each destination would recieve only part of the data available in the replication slot.
Using logical replication increases disk space used on the database server. The additional data is stored until it is consumed.



Documentation Source:
airbyte.com/tutorials/incremental-data-synchronization.txt

Documentation Title:
Incremental data synchronization between Postgres databases | Airbyte

Documentation Content:
Create a connection between the source and destination
In this section you will create a connection that will be used for demonstrating the functionality of database replication with
Incremental Sync | Append
.
This new connection will make use of the connectors that you have just created.
Create a new connection by clicking on
Connections
and then on
+ New connection
as shown below (Note that this button may appear in the top right corner if you already have some connections instantiated):
‍
Then select the
Incremental-source
source as follows:
‍
Select the
Incremental-destination
as follows:
‍
You will see a set up page as shown below. Set the name of the connection to
incremental-sync-demo
, and configure it as shown below:
‍
There are a few areas that are annotated in the above configuration:
Define the name which will identify this connection - in this case I have called it
incremental-sync-demo
.
Select the
incremental append
replication mode for the table called
table_one
.
Select
updated_at
as the cursor for the
table_one
table.
After you click on
Set up connection
,
the initial sync will start. Once it completes you should see the following status in the
Sync History
:
‍
Make a note of the
job ID
and the
attempt ID
which in this case are 149 and 0 respectively, as can be seen in the path to the
logs.log
(/tmp/workspace/149/0/logs.log) in the screenshot above. You will need these values to find the SQL code used for the first
incremental append
sync.
Initial creation: Overview
In the first synchronization, Airbyte replicates all of the records from the source table into a raw table in the destination database. Then, dbt-generated SQL commands are executed to normalize the raw data into the final destination table as shown below:
‍
Initial creation: Look at the Postgres destination
After the first sync has completed you can take a look at the Postgres destination to see how the replicated data looks.



