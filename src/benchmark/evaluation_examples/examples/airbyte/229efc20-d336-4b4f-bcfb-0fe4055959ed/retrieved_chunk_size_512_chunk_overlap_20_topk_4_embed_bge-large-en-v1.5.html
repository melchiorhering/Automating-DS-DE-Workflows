Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/local-json.html

Documentation Title:
Local JSON | Airbyte Documentation

Documentation Content:
It will not work otherwise). You allow it with "File sharing" in <code>Settings -&gt; Resources -&gt; File sharing -&gt; add the one or two above folder</code>and hit the "Apply &amp; restart" button.</p></div><h3>Example:<a>​</a></h3><ul><li>If <code>destination_path</code>is set to <code>/local/cars/models</code></li><li>the local mount is using the <code>/tmp/airbyte_local</code>default</li><li>then all data will be written to <code>/tmp/airbyte_local/cars/models</code>directory.</li></ul><h2>Access Replicated Data Files<a>​</a></h2><p>If your Airbyte instance is running on the same computer that you are navigating with, you can open your browser and enter <a>file:///tmp/airbyte_local</a>to look at the replicated data locally. If the first approach fails or if your Airbyte instance is running on a remote server, follow the following steps to access the replicated files:</p><ol><li>Access the scheduler container using <code>docker exec -it airbyte-server bash</code></li><li>Navigate to the default local mount using <code>cd /tmp/airbyte_local</code></li><li>Navigate to the replicated file directory you specified when you created the destination, using <code>cd /{destination_path}</code></li><li>List files containing the replicated data using <code>ls</code></li><li>Execute <code>cat {filename}</code>to display the data in a particular file</li></ol><p>You can also copy the output file to your host machine, the following command will copy the file to the current working directory you are using:</p><span>docker cp airbyte-server:/tmp/airbyte_local/{destination_path}/{filename}.jsonl .</span><p>Note: If you are running Airbyte on Windows with Docker backed by WSL2, you have to use similar step as above or refer to this <a>link</a>for an alternative approach.



Documentation Source:
airbyte.com/docs.airbyte.com/using-airbyte/getting-started/set-up-a-connection.html

Documentation Title:
Set up a Connection | Airbyte Documentation

Documentation Content:
you will now see three tabs created in your Google Sheet, <code>products</code>, <code>users</code>, and <code>purchases</code>.</p><div><p>If you followed along and created your own connection using a <code>Local JSON</code>destination, you can use this command to check the file's contents to make sure the replication worked as intended (be sure to replace YOUR_PATH with the path you chose in your destination setup, and YOUR_STREAM_NAME with the name of an actual stream you replicated):</p><span>cat /tmp/airbyte_local/YOUR_PATH/_airbyte_raw_YOUR_STREAM_NAME.jsonl</span><p>You should see a list of JSON objects, each containing a unique <code>airbyte_ab_id</code>, an <code>emitted_at</code>timestamp, and <code>airbyte_data</code>containing the extracted record.</p><div><div>tip</div><p>If you are using Airbyte on Windows with WSL2 and Docker, refer to <a>this guide</a>to locate the replicated folder and file.</p></div></div></div></div><h2>What's next?<a>​</a></h2><p>Congratulations on successfully setting up your first connection using Airbyte! We hope that this will be just the first step on your journey with us. We support a large, ever-growing <a>catalog of sources and destinations</a>, and you can even <a>contribute your own</a>.</p><p>If you have any questions at all, please reach out to us on <a>Slack</a>. If you would like to see a missing feature or connector added, please create an issue on our <a>Github</a>.



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/local-json.html

Documentation Title:
Local JSON | Airbyte Documentation

Documentation Content:
Each file will a collections of <code>json</code>objects containing 3 fields:</p><ul><li><code>_airbyte_ab_id</code>: a uuid assigned by Airbyte to each event that is processed.</li><li><code>_airbyte_emitted_at</code>: a timestamp representing when the event was pulled from the data source.</li><li><code>_airbyte_data</code>: a json blob representing with the extracted data.</li></ul><h4>Features<a>​</a></h4><table><tr><th>Feature</th><th>Supported</th></tr><tbody><tr><td>Full Refresh Sync</td><td>Yes</td></tr><tr><td>Incremental - Append Sync</td><td>Yes</td></tr><tr><td>Incremental - Append + Deduped</td><td>No</td></tr><tr><td>Namespaces</td><td>No</td></tr></tbody></table><h4>Performance considerations<a>​</a></h4><p>This integration will be constrained by the speed at which your filesystem accepts writes.</p><h2>Getting Started<a>​</a></h2><p>The <code>destination_path</code>will always start with <code>/local</code>whether it is specified by the user or not. Any directory nesting within local will be mapped onto the local mount.</p><p>By default, the <code>LOCAL_ROOT</code>env variable in the <code>.env</code>file is set <code>/tmp/airbyte_local</code>.</p><p>The local mount is mounted by Docker onto <code>LOCAL_ROOT</code>. This means the <code>/local</code>is substituted by <code>/tmp/airbyte_local</code>by default.</p><div><div>caution</div><p>Please make sure that Docker Desktop has access to <code>/tmp</code>(and <code>/private</code>on a MacOS, as /tmp has a symlink that points to /private. It will not work otherwise).



Documentation Source:
airbyte.com/tutorials/how-to-use-airflow-and-airbyte-together.html

Documentation Title:
A step-by-step guide to setting up and configuring Airbyte and Airflow to work together | Airbyte

Documentation Content:
For this tutorial I use the following default values: </p><code>BASIC_AUTH_USERNAME=airbyte
BASIC_AUTH_PASSWORD=password
</code><p>Once Airbyte is running, in your browser type in localhost:8000, which should prompt you for a username and password as follows:</p><figcaption>Airbyte OSS login prompt</figcaption><h2>Create a connection</h2><p>Create a connection that sends data from the <strong>Sample Data (Faker)</strong>source to the <strong>Local JSON</strong>(file system) output. Click on “Create your first connection” as shown below:</p><figcaption>Create your first connection prompt</figcaption><p>‍</p><p>You should then see an option to set up a source connection. Select the Faker source from the dropdown as shown below.</p><figcaption>Select Sample Data (Faker) as a source</figcaption><p>‍</p><p>After selecting Sample Data as the source, you will see a screen that should look as follows. Click on <strong>Set up source</strong>as shown below. </p><figcaption>Configure Sample Data (Faker) as a source</figcaption><p>‍</p><p>You will then wait a few seconds for the Sample Data source to be verified, at which point you will be prompted to configure the destination that will be used for the connection. Select <strong>Local JSON</strong>as shown below:</p><figcaption>Select Local JSON as a destination</figcaption><p>‍</p><p>After selecting Local JSON as the output, you will need to specify where the JSON files should be written. By default the path that you specify will be located inside <strong>/tmp/airbyte_local</strong>. In this tutorial I set the destination to <strong>/json_from_faker</strong>, which means that the data will be copied to<strong>/tmp/airbyte_local/json_from_faker</strong>on the localhost where Airbyte is running. After specifying the Destination Path, click on Set up destination.



