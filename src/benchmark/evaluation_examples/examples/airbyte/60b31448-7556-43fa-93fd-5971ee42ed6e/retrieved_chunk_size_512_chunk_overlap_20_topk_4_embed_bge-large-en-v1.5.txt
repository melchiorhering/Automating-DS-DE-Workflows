Documentation Source:
airbyte.com/docs.airbyte.com/using-airbyte/getting-started/set-up-a-connection.txt

Documentation Title:
Set up a Connection | Airbyte Documentation

Documentation Content:
Set up a Connection | Airbyte Documentation
Skip to main content
About Airbyte
Tutorials
Support
Cloud Status
Try Airbyte Cloud
Search
Airbyte Connectors
Connector Catalog
Build a Connector
Connector Support Levels
Using Airbyte
Getting Started
Core Concepts
Add a Source
Add a Destination
Set up a Connection
Configuring Connections
Managing Syncs
Managing Airbyte
Deploy Airbyte
Self-Managed Enterprise
Upgrading Airbyte
Configuring Airbyte
Access Management
Airbyte at Scale
Security
Integrating with Airbyte
Account Management
Developer Guides
API documentation
Terraform Documentation
Using PyAirbyte
Understand Airbyte
Contribute to Airbyte
Licenses
Community
Getting Support
Code of Conduct
Product Updates
Roadmap
Release Notes
Getting Started
Set up a Connection
On this page
Set up a Connection
Available
Cloud
Available
Self-Managed Community (OSS)
Available
Self-Managed Enterprise
Now that you've learned how to set up your first
source
and
destination
, it's time to finish the setup by creating your very first connection!
On the left side of your main Airbyte dashboard, select
Connections
. You will be prompted to choose which source and destination to use for this connection. For this example, we'll use the
Google Sheets
source and the destination you previously set up, either
Local JSON
or
Google Sheets
.
Configure the connection
‚Äã
Once you've chosen your source and destination you can configure the connection. You'll first be asked a few questions about how your data should sync, these correlate to our sync modes which you can read more about on
this page
.
Most users select "Mirror Source", which will simply copy the data from the source to the destination where you'll see one row in the destination for each row in the source. If you prefer to Append Historical Changes or take a Full Snapshot with each sync, you can optionally select those options, but keep in mind those will create duplicate records in your destination. The sync mode we choose for all the enabled streams will reflect your selection here.
Next, you can toggle which streams you want to replicate.



Documentation Source:
airbyte.com/quickstart/e-commerce-analytics-with-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
E-commerce Analytics Stack with Airbyte, dbt, Dagster and BigQuery | Airbyte

Documentation Content:
Setting Up Airbyte Connectors Using the UI
Start by launching the Airbyte UI by going to
http://localhost:8000/
in your browser. Then:
1. Create a source
:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
2. Create a destination
:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
3. Create a connection
:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery. Here‚Äôs a step-by-step guide to help you set this up:
1. Navigate to the dbt Project Directory
:
Move to the directory containing the dbt configuration:
cd ../../dbt_project
2. Update Connection Details
:
You'll find a <span class="text-style-code">profiles.yml</span> file within the directory. This file contains configurations for dbt to connect with your data platform. Update this file with your BigQuery connection details. Specifically, you need to update the Service Account JSON file path and your BigQuery project ID.
Provide your BigQuery project ID in the database field of the <span class="text-style-code">dbt_project/models/sources/faker_sources.yml</span> file.



Documentation Source:
airbyte.com/tutorials/building-an-e-commerce-data-pipeline-a-hands-on-guide-to-using-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
How to build E-commerce Data Pipeline with Airbyte? | Airbyte

Documentation Content:
Create a source:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
Look fo Faker source connector
Create a Faker source
2. Create a destination:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
Look for BigQuery destination connector
Create a BigQuery destination
3. Create a connection:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
For this project, leave the ‚Äúreplication frequency‚Äù as ‚ÄúManual‚Äù, since we will orchestrate the syncs with Dagster.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
‚Äç
Establish a connector between Faker and BigQuery
4. Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery.
1. Navigate to the dbt Project Directory:
Move to the dbt project directory in your project's file structure.
cd ../../dbt_project
This directory contains all the dbt-related configurations and SQL models.
2. Update Connection Details:
Within this directory, you'll find a <span class="text-style-code">profiles.yml file</span>. This file holds the configuration for dbt to connect to BigQuery.



Documentation Source:
airbyte.com/docs.airbyte.com/using-airbyte/getting-started/set-up-a-connection.txt

Documentation Title:
Set up a Connection | Airbyte Documentation

Documentation Content:
Next, you can toggle which streams you want to replicate. Our test data consists of three streams, which we've enabled and set to
Incremental - Append + Deduped
sync mode.
Your sync mode is already determined by your selection above, but you can change the sync mode for an individual stream. You can also select a cursor or primary key to enable incremental and/or deduplication. For more information on the nature of each sync mode supported by Airbyte, see
this page
.
You can also select individual fields to sync on this page. Expand the fields available by clicking any stream. This is helpful when you have security concerns or don't want to sync all the data from the source.
Click
Next
to complete your stream setup and move to the connection configuration. This is where you'll set up how often your data will sync and where it will live in the destination. For this demo, we'll set the connection to run at 8 AM every day and sync the connection to a custom namespace with a stream prefix.
note
To ensure your data is synced to the correct place, see our examples for
Destination Namespace
Once you've set up all the connection settings, click "Set up connection". You've successfully set up your first data pipeline with Airbyte. Your first sync is about to begin!
Connection Overview
‚Äã
Once you've finished setting up the connection, you will be automatically redirected to a connection overview containing all the tools you need to keep track of your connection.
Here's a basic overview of the tabs and their use:
The
Status
tab shows you an overview of your connector's sync health.
The
Job History
tab allows you to check the logs for each sync. If you encounter any errors or unexpected behaviors during a sync, checking the logs is always a good first step to finding the cause and solution.
The
Schema
tab allows you to modify the streams you chose during the connection setup.
The
Transformation
tab allows you to set up a custom post-sync transformations using dbt.
The
Settings
tab contains the connection settings, and the option to delete the connection if you no longer wish to use it.



