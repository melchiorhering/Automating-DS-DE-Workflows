Documentation Source:
cloud.google.com/bigquery/docs/inference-tutorial-resnet.html

Documentation Title:
Tutorial: Run inference on an object table by using a classification model  |  BigQuery  |  Google Cloud

Documentation Content:
data quality</span><span>Monitor Data Transfer Service</span><span>Monitor materialized views</span><span>Monitor reservations</span><span>Dashboards, charts and alerts</span></ul></div><div><span>Audit workloads</span><ul><span>Introduction</span><span>Audit policy tags</span><span>View Data Policy audit logs</span><span>Data Transfer Service audit logs</span><span>Analytics Hub audit logging</span><span>BigQuery audit logs reference</span><span>Migrate audit logs</span><span>BigLake API audit logs</span></ul></div><div><span>Optimize resources</span><ul><div><span>Control costs</span><ul><span>Estimate and control query costs</span><span>Custom cost controls</span></ul></div><div><span>Optimize with recommendations</span><ul><span>View cluster and partition recommendations</span><span>Apply cluster and partition recommendations</span><span>Manage materialized view recommendations</span></ul></div><div><span>Organize with labels</span><ul><span>Introduction</span><span>Add labels</span><span>View labels</span><span>Update labels</span><span>Filter using labels</span><span>Delete labels</span></ul></div><div><span>Manage data quality</span><ul><span>Monitor data quality with scans</span><span>Data Catalog overview</span><span>Work with Data Catalog</span></ul></div></ul></div><span>Govern</span><span>Introduction</span><div><span>Control access to resources</span><ul><span>Introduction</span><span>Control access to resources with IAM</span><div><span>Control access with authorization</span><ul><span>Authorized datasets</span><span>Authorized routines</span><span>Authorized views</span></ul></div><span>Control access with VPC service controls</span><span>Control table and dataset access with tags</span><span>Control access with conditions</span></ul></div><div><span>Control column and row access</span><ul><div><span>Control access to table



Documentation Source:
cloud.google.com/bigquery/docs/analyze-data-tableau.html

Documentation Title:
Quickstart: Analyze BigQuery data with BI Engine and Tableau  |  BigQuery: Cloud Data Warehouse  |  Google Cloud

Documentation Content:
For more information,
see <a>Troubleshooting Errors</a>.</p></section><section><h2>Create a BigQuery dataset</h2><p>The first step is to create a BigQuery dataset to store your
BI Engine-managed table. To create your dataset, follow these
steps:</p><ol><li><p>In the Google Cloud console, go to the BigQuery page.</p><a>Go to BigQuery</a></li><p>In the navigation panel, in the <strong>Explorer</strong>panel, click your project
name.</p><p>In the details panel, click <span>more_vert</span><strong>View actions</strong>, and then click <strong>Create dataset</strong>.</p><li><p>On the <strong>Create dataset</strong>page, do the following:</p><ul><li>For <strong>Dataset ID</strong>, enter <code>biengine_tutorial</code>.</li><p>For <strong>Data location</strong>, choose <strong>us (multiple regions in United
States)</strong>, the <a>multi-region
location</a>where public datasets
are stored.</p><p>For this tutorial, you can select <strong>Enable table expiration</strong>, and then
specify the number of days before the table expires.</p></ul></li><p>Leave all of the other default settings in place and click <strong>Create dataset</strong>.</p></ol><h2>Create a table by copying data from a public dataset</h2><p>This tutorial uses a dataset available through the
<a>Google Cloud Public Dataset Program</a>. Public datasets
are datasets that BigQuery hosts for you to access and integrate
into your applications.</p><p>In this section, you create a table by copying data from the
<a>San Francisco 311 service requests</a>dataset.



Documentation Source:
cloud.google.com/bigquery/docs/analyze-data-tableau.html

Documentation Title:
Quickstart: Analyze BigQuery data with BI Engine and Tableau  |  BigQuery: Cloud Data Warehouse  |  Google Cloud

Documentation Content:
You can explore the dataset by using the
<a>Google Cloud console</a>.</p><h3>Create your table</h3><p>To create your table, follow these steps:</p><ol><li><p>In the Google Cloud console, go to the BigQuery page.</p><a>Go to BigQuery</a></li><p>In the <strong>Explorer</strong>panel, search for <code>san_francisco_311</code>.</p><p>In the <strong>Explorer</strong>panel, expand <strong>san_francisco_311</strong>and click the
<strong>311_service_requests</strong>table.</p><p>In the Explorer toolbar, click <strong>Copy</strong>.</p><li><p>In the <strong>Copy table</strong>dialog, in the <strong>Destination</strong>section, do the
following:</p><ul><li>For <strong>Project name</strong>, click <strong>Browse</strong>, and then select your project.</li><li>For <strong>Dataset name</strong>, select <strong>biengine_tutorial</strong>.</li><p>For <strong>Table name</strong>, enter <code>311_service_requests_copy</code>.</p></ul></li><p>Click <strong>Copy</strong>.</p><p>Optional: After the copy job is complete, verify the table contents by expanding
<strong><var>PROJECT_NAME</var><span>&gt;</span>biengine_tutorial</strong>and
clicking <strong>311_service_requests_copy <span>&gt;</span>Preview</strong>.



Documentation Source:
cloud.google.com/bigquery/docs/analysis-rules.html

Documentation Title:
Restrict data access using analysis rules  |  BigQuery  |  Google Cloud

Documentation Content:
CREATE TABLE mydataset.ExamTable AS (
  SELECT "Hansen" AS last_name, "P91" AS test_id, 510 AS test_score UNION ALL
  SELECT "Wang", "U25", 500 UNION ALL
  SELECT "Wang", "C83", 520 UNION ALL
  SELECT "Wang", "U25", 460 UNION ALL
  SELECT "Hansen", "C83", 420 UNION ALL
  SELECT "Hansen", "C83", 560 UNION ALL
  SELECT "Devi", "U25", 580 UNION ALL
  SELECT "Devi", "P91", 480 UNION ALL
  SELECT "Ivanov", "U25", 490 UNION ALL
  SELECT "Ivanov", "P91", 540 UNION ALL
  SELECT "Silva", "U25", 550);

-- Create a table called StudentTable.
CREATE TABLE mydataset.StudentTable AS (
  SELECT "Hansen" AS last_name, 510 AS test_score UNION ALL
  SELECT "Wang", 500 UNION ALL
  SELECT "Devi", 580 UNION ALL
  SELECT "Ivanov", 490 UNION ALL
  SELECT "Silva", 550);

-- Create a view that includes ExamTable.
CREATE VIEW mydataset.ExamView
OPTIONS(
  privacy_policy= '{"join_restriction_policy": {"join_condition": "JOIN_ANY", "join_allowed_columns": ["test_score"]}}'
)
AS ( SELECT * FROM mydataset.ExamTable );

-- Query the ExamView view.
SELECT *
FROM mydataset.ExamView INNER JOIN mydataset.StudentTable USING (test_score)
GROUP BY test_id;

-- These results will change each time you run the query.
-- Smaller aggregations might be removed.
/*---------+--------------------*
 | test_id | average_test_score |
 +---------+--------------------+
 | P91     | ???                |
 | U25     | ???                |
 *---------+--------------------*/
</code><h4>Block a join operation with no required column</h4><p>You can block a join operation if it doesn't include at least one
required column.



