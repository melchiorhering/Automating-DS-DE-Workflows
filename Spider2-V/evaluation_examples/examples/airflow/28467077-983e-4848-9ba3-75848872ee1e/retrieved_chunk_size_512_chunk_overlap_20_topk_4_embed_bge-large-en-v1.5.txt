Documentation Source:
docs.astronomer.io/learn/connections/postgres.txt

Documentation Title:
Create a Postgres connection in Airflow | Astronomer Documentation

Documentation Content:
Refer to the following documents to for more information about retrieveing these values:
AWS: Connect to Postgres running on
RDS
GCP: Connect to Postgres running on
Cloud SQL
Azure: Connect to Postgres running on an
Azure database
For example, if you're running Postgres in a Relational Data Store (RDS) in AWS, complete the following steps to retrieve these values:
In your AWS console, select your region, then go to the RDS service and select your Postgres database.
Open the
Connectivity & security
tab and copy the
Endpoint
and
Port
.
Follow the AWS instructions to
create a user
and
grant a role to the user
that Airflow will use to connect to Postgres. Copy the username and password.
(Optional) To use a specific schema, copy the name of the schema. If you skip this, the default schema
public
will be used.
Create your connection
​
Open your Astro project and add the following line to your
requirements.txt
file:
apache-airflow-providers-postgres
This will install the Postgres provider package, which makes the Postgres connection type available in Airflow.
Run
astro dev restart
to restart your local Airflow environment and apply your changes in
requirements.txt
.
In the Airflow UI for your local Airflow environment, go to
Admin
>
Connections
. Click
+
to add a new connection, then choose
Postgres
as the connection type.
Fill out the following connection fields using the information you retrieved from
Get connection details
:
Connection Id
: Enter a name for the connection.
Host
: Enter your Postgres server's host/ endpoint URL/ server name/ instance ID.
Schema
: Enter your schema name.
Login
: Enter your username.
Password
: Enter your password.
Port
: Enter your Postgres server's
Port
.
Click
Test
. After the connection test succeeds, click
Save
.
How it works
​
Airflow uses the
psycopg2
python library to connect to Postgres through the
PostgresHook
. You can also directly use the PostgresHook to create your own custom operators.



Documentation Source:
docs.astronomer.io/learn/connections.txt

Documentation Title:
Manage connections in Apache Airflow | Astronomer Documentation

Documentation Content:
Go to
Admin
>
Connections
.
Airflow doesn't provide any preconfigured connections. To create a new connection, click the blue
+
button.
As you update the
Connection Type
field, notice how the other available fields change. Each connection type requires different kinds of information. Specific connection   types are only available in the dropdown list when the relevant provider is installed in your Airflow environment.
You don't have to specify every field for most connections. However, the values marked as required in the Airflow UI can be misleading. For example, to set up a connection to a PostgreSQL database, you need to reference the
PostgreSQL provider documentation
to learn that the connection requires a
Host
, a user name as
login
, and a password in the
password
field.
Any parameters that don't have specific fields in the connection form can be defined in the
Extra
field as a JSON dictionary. For example, you can add the
sslmode
or a client
sslkey
in the
Extra
field of your PostgreSQL connection.
You can test some connection types from the Airflow UI with the
Test
button if you enable
test_connection
in the Airflow config
. After running a connection test, a message shows either a success confirmation or an error message. When using the
Test
button, the connection to your external tool is made from the webserver component of Airflow. See also
Testing connections in the Airflow documentation
.
Define connections with environment variables
​
Connections can also be defined using environment variables. If you use the Astro CLI, you can use the
.env
file for local development or specify environment variables in your project's Dockerfile.
Note
: If you are synchronizing your project to a remote repository, don't save sensitive information in your Dockerfile. In this case, using either a secrets backend, Airflow connections defined in the UI, or
.env
locally are preferred to avoid exposing secrets in plain text.
The environment variable used for the connection must be formatted as
AIRFLOW_CONN_YOURCONNID
and can be provided as a Uniform Resource Identifier (URI) or in JSON.



Documentation Source:
docs.astronomer.io/learn/connections/postgres.txt

Documentation Title:
Create a Postgres connection in Airflow | Astronomer Documentation

Documentation Content:
Create a Postgres connection in Airflow | Astronomer Documentation
Skip to main content
Docs
Docs
Find what you're looking for
Learn About Astronomer
Get Started Free
Home
Astro
Astro CLI
Software
Learn
Try Astro
Overview
Get started
Airflow concepts
Airflow tutorials
Integrations & connections
Amazon SageMaker
Apache Kafka/Confluent
Azure Blob Storage
Azure Container Instances
Azure Data Factory
Microsoft Entra Workload ID
BigQuery
Cohere
Databricks
dbt Cloud
dbt Core
DuckDB
Fivetran
Great Expectations
Jupyter notebook
Marquez
MLflow
MongoDB
Microsoft SQL Server
OpenAI
OpenSearch
pgvector
Pinecone
Postgres
Redshift
Snowflake
Soda Core
Weaviate
Weights and Biases
Use cases
Airflow glossary
Support Knowledge Base
Office Hours
Webinars
Astro Status
Integrations & connections
Postgres
On this page
Create a Postgres connection in Airflow
Postgres
is a free and open source relational database system. Integrating Postgres with Airflow allows you to interact with your Postgres database, run queries, ans load or export data from an Airflow DAG.
This guide provides the basic setup for creating a Postgres connection.
Prerequisites
​
The
Astro CLI
.
A locally running
Astro project
.
A Postgres database running in the cloud or on-premises.
Permission
to access your Postgres database from your local Airflow environment.
Get connection details
​
A connection from Airflow to Postgres requires the following information:
Host (also known as the endpoint URL, server name, or instance ID based on your cloud provider)
Port (default is 5432)
Username
Password
Schema (default is
public
)
The method to retrieve these values will vary based which cloud provider you use to host Microsoft SQL Server.



Documentation Source:
docs.astronomer.io/learn/marquez.txt

Documentation Title:
Integrate OpenLineage and Airflow with Marquez | Astronomer Documentation

Documentation Content:
To run this example in your local environment, complete the following steps:
Using
psql
, create a local Postgres database in the same container as the Airflow metastore:
psql
-h
localhost
-p
5435
-U
postgres
# enter password `postgres` when prompted
create database lineagetutorial
;
\
c lineagetutorial
;
If you already have a Postgres database or are using a different type of database you can skip this step. Note that this database should be separate from the Airflow and Marquez metastores.
Run the following SQL statements in your new database to create and populate two source tables:
CREATE
TABLE
IF
NOT
EXISTS
adoption_center_1
(
date
DATE
,
type
VARCHAR
,
name
VARCHAR
,
age
INTEGER
)
;
CREATE
TABLE
IF
NOT
EXISTS
adoption_center_2
(
date
DATE
,
type
VARCHAR
,
name
VARCHAR
,
age
INTEGER
)
;
INSERT
INTO
adoption_center_1
(
date
,
type
,
name
,
age
)
VALUES
(
'2022-01-01'
,
'Dog'
,
'Bingo'
,
4
)
,
(
'2022-02-02'
,
'Cat'
,
'Bob'
,
7
)
,
(
'2022-03-04'
,
'Fish'
,
'Bubbles'
,
2
)
;
INSERT
INTO
adoption_center_2
(
date
,
type
,
name
,
age
)
VALUES
(
'2022-06-10'
,
'Horse'
,
'Seabiscuit'
,
4
)
,
(
'2022-07-15'
,
'Snake'
,
'Stripes'
,
8
)
,
(
'2022-08-07'
,
'Rabbit'
,
'Hops'
,
3
)
;
Step 4: Configure your Airflow connection
​
The connection you configure will connect to the Postgres database you created in
Step 3
.
In the Airflow UI, go to
Admin
->
Connections
.
Create a new connection named
postgres_default
and choose the
postgres
connection type.



