Documentation Source:
docs.astronomer.io/astro/manage-dags.txt

Documentation Title:
Manage DAG runs from the Astro UI | Astronomer Documentation

Documentation Content:
Manage DAG runs from the Astro UI | Astronomer Documentation
Skip to main content
Docs
Docs
Find what you're looking for
Learn About Astronomer
Get Started Free
Home
Astro
Astro CLI
Software
Learn
Try Astro
Overview
Get started
Develop
Deploy code
Manage Deployments
Create a Deployment
Deployment settings
Executors
Worker queues
Environment variables
Secrets backend
Manage DAG runs
Automation & CI/CD
Observability
Administration
Release notes
Best practices
Reference
Astro API
Support Knowledge Base
Office Hours
Webinars
Astro Status
Manage Deployments
Manage DAG runs
On this page
Manage DAG runs from the Astro UI
You can perform some common Airflow UI actions from the Astro UI, including:
Marking DAG and task runs as succeeded/failed.
Retrying DAG and task runs.
Viewing DAG and task run statuses.
These actions are available on the
DAGs
page, where you can see detailed information about a specific DAG. This page compiles the most commonly used information and actions from the Airflow UI into one place so that you can manage your DAGs without switching between the Airflow UI and Astro UI.
Access the DAGs page in the Astro UI
​
In the Astro UI, select a Deployment.
Click
DAGs
.
Click the name of the DAG that you want to manage.
Available actions
​
The actions and views on this page are functionally identical to certain actions in the Airflow UI. Use the following table to understand each available Astro UI action and its equivalent action in the Airflow UI.
User action
DAGs
page workflow
Equivalent Airflow UI workflow
Trigger a DAG run.
Click
Run
.
Click the
Play
icon on the
DAGs
page.
View the DAG run
grid
.
None. DAG code appears by default.
Click the DAG name on the
DAGs
page.
View the
graph
for a DAG run.
None. DAG code appears by default.
Click the DAG name on the
DAGs
page, then click
Graph
.
View
task run logs
.
Click the task run in the DAG run grid, then click
Logs
.



Documentation Source:
docs.astronomer.io/astro/migrate-gcc.txt

Documentation Title:
Migrate to Astro from Google Cloud Composer | Astronomer Documentation

Documentation Content:
In your Astro project directory, run
astro dev parse
to check for any parsing errors in your DAGs.
Run
astro run <dag-id>
to test a specific DAG. This command compiles your DAG and runs it in a single Airflow worker container based on your Astro project configurations.
Run
astro dev start
to start a complete Airflow environment on your local machine. After your project starts up, you can access the Airflow UI at
localhost:8080
. See
Troubleshoot your local Airflow environment
.
Note that your migrated Airflow variables and connections are not available locally. You must deploy your project to Astro to test these resources.
Step 9: Deploy to Astro
​
Run the following command to authenticate to Astro:
astro login
Run the following command to deploy your project
astro deploy
This command returns a list of Deployments available in your Workspace and prompts you to pick one.
In the Astro UI, open your Deployment and click
Open Airflow
. Confirm that you can see your deployed DAGs in the Airflow UI.
Step 10: Cut over from your source Airflow environment to Astro
​
After you successfully deploy your code to Astro, you need to migrate your workloads from your source Airflow environment to Astro on a DAG-by-DAG basis. Depending on how your workloads are set up, Astronomer recommends letting DAG owners determine the order to migrate and test DAGs.
You can complete the following steps in the few days or weeks following your migration set up. Provide updates to your Astronomer Data Engineer as they continue to assist you through the process and any solve any difficulties that arise.
Continue to validate and move your DAGs until you have fully cut over your source Airflow instance. After you finish migrating from your source Airflow environment, repeat the complete migration process for any other Airflow instances in your source Airflow environment.
Confirm connections and variables
​
In the Airflow UI for your Deployment,
test all connections
that you migrated from your source Airflow environment.
Additionally, check Airflow variable values in
Admin
>
Variables
.
Test and validate DAGs in Astro
​
To create a strategy for testing DAGs, determine which DAGs need the most care when running and testing them.



Documentation Source:
docs.astronomer.io/astro/migrate-mwaa.txt

Documentation Title:
Migrate to Astro from Amazon MWAA | Astronomer Documentation

Documentation Content:
You must deploy your project to Astro to test these Airflow objects.
Step 9: Deploy to Astro
​
Run the following command to authenticate to Astro:
astro login
Run the following command to deploy your project
astro deploy
This command returns a list of Deployments available in your Workspace and prompts you to pick one.
In the Astro UI, open your Deployment and click
Open Airflow
. Confirm that you can see your deployed DAGs in the Airflow UI.
Step 10: Cut over from your source Airflow environment to Astro
​
After you successfully deploy your code to Astro, you need to migrate your workloads from your source Airflow environment to Astro on a DAG-by-DAG basis. Depending on how your workloads are set up, Astronomer recommends letting DAG owners determine the order to migrate and test DAGs.
You can complete the following steps in the few days or weeks following your migration set up. Provide updates to your Astronomer Data Engineer as they continue to assist you through the process and any solve any difficulties that arise.
Continue to validate and move your DAGs until you have fully cut over your source Airflow instance. After you finish migrating from your source Airflow environment, repeat the complete migration process for any other Airflow instances in your source Airflow environment.
Confirm connections and variables
​
In the Airflow UI for your Deployment,
test all connections
that you migrated from your source Airflow environment.
Additionally, check Airflow variable values in
Admin
>
Variables
.
Test and validate DAGs in Astro
​
To create a strategy for testing DAGs, determine which DAGs need the most care when running and testing them.
If your DAG workflow is idempotent and can run twice or more without negative effects, you can run and test these DAGs with minimal risk. If your DAG workflow is non-idempotent and can become invalid when you rerun it, you should test the DAG with more caution and downtime.
Cut over DAGs to Astro using Starship
​
Starship includes features for simultaneously pausing DAGs in your source Airflow environment and starting them on Astro. This allows you to cut over your production workflows without downtime.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow.txt

Documentation Title:
Get started with Apache Airflow, Part 1: Write and run your first DAG | Astronomer Documentation

Documentation Content:
In your terminal, open your Astro project directory and run the following command:
astro dev start
Starting Airflow for the first time can take 1 to 3 minutes. Once your local environment is ready, the CLI automatically opens a new tab or window in your default web browser to the Airflow UI at
https://localhost:8080
.
info
If port 8080 or 5432 are in use on your machine, Airflow won't be able to start. To run Airflow on alternative ports, run:
astro config
set
webserver.port
<
available-port
>
astro config
set
postgres.port
<
available-port
>
Step 3: Log in to the Airflow UI
​
The
Airflow UI
is essential for managing Airflow. It contains information about your DAGs and is the best place to create and update Airflow connections to third-party data services.
To access the Airflow UI, open
http://localhost:8080/
in a browser and log in with
admin
for both your username and password.
The default page in the Airflow UI is the
DAGs
page, which shows an overview of all DAGs in your Airflow environment:
Each DAG is listed with a few of its properties, including tags, owner, previous runs, schedule, timestamp of the last and next run, and the states of recent tasks. Because you haven't run any DAGs yet, the
Runs
and
Recent Tasks
sections are empty. Let's fix that!
Step 4: Trigger a DAG run
​
The
example_astronauts
DAG in your Astro project is a simple ETL pipeline with two tasks:
get_astronauts
queries the
Open Notify API
for information about astronauts currently in space. The task returns the list of dictionaries containing the name and the spacecraft of all astronauts currently in space, which is passed to the second task in the DAG. This tutorial does not explain how to pass data between tasks, but you can learn more about it in the
Pass data between tasks
guide.
print_astronaut_craft
is a task that uses dynamic mapping to create and run a task instance for each Astronaut in space.



