Documentation Source:
docs.astronomer.io/astro/view-logs.txt

Documentation Title:
View Deployment logs | Astronomer Documentation

Documentation Content:
Click the
Logs
tab to switch from
Graph
view.
View task logs in the Airflow UI
​
Access the Airflow UI.
To access the Airflow UI for a Deployment, open the Deployment in the Astro UI and click
Open Airflow
.
To access the Airflow UI in a local environment, open a browser and go to
http://localhost:8080
.
Click a DAG.
Click
Graph
.
Click a task run.
Click
Instance Details
.
Click
Log
.
See also
​
Export task logs and metrics to Datadog
Export task logs to AWS Cloudwatch
Was this page helpful?
Yes
No
Sign up for Developer Updates
Get a summary of new Astro features once a month.
Submit
You can unsubscribe at any time.
By proceeding you agree to our
Privacy Policy
, our
Website Terms
and to receive emails from Astronomer.
Edit this page
Previous
Deployment API keys (Deprecated)
Next
DAGs
Airflow Component Logs
Airflow component log levels
View Airflow component logs in the Astro UI
View Airflow component logs locally
Airflow task logs
Airflow task log levels
View task logs on the Astro UI
View task logs in the Airflow UI
See also
Legal
·
Privacy
·
Security
·
Cookie Preferences
© Astronomer 2023. Various trademarks held by their respective owners.



Documentation Source:
docs.astronomer.io/astro/migrate-gcc.txt

Documentation Title:
Migrate to Astro from Google Cloud Composer | Astronomer Documentation

Documentation Content:
Ensure that the
Astronomer Product
toggle is set to
Astro
.
In the
Airflow URL
section, fill in the fields so that the complete URL on the page matches the URL of the Airflow UI for the Deployment you're migrating to.
Specify your API token in the
Token
field. Starship will confirm that it has access to your Deployment.
Click
Connections
. In the table that appears, click
Migrate
for each connection that you want to migrate to Astro. After the migration is complete, the status
Migrated ✅
appears.
Click
Pools
. In the table that appears, click
Migrate
for each connection that you want to migrate to Astro. After the migration is complete, the status
Migrated ✅
appears.
Click
Variables
. In the table that appears, click
Migrate
for each variable that you want to migrate to Astro. After the migration is complete, the status
Migrated ✅
appears.
Click
Environment variables
. In the table that appears, check the box for each environment variable that you want to migrate to Astro, then click
Migrate
. After the migration is complete, the status
Migrated ✅
appears.
Click
DAG History
. In the table that appears, check the box for each DAG whose history you want to migrate to Astro, then click
Migrate
. After the migration is complete, the status
Migrated ✅
appears.
Refer to the
Configuration
detailed instructions on using the operator.
Log in to Astro. In the Astro UI, open the Deployment you're migrating to.
Click
Open Airflow
to open the Airflow UI for the Deployment. Copy the URL for the home page. It should look similar to
https://<your-organization>.astronomer.run/<id>/home
.
Create a Deployment API token for the Deployment. The token should minimally have permissions to update the Deployment and deploy code. Copy this token. See
Create and manage Deployment API tokens
for additional setup steps.
Add the following DAG to your source Airflow environment:
from
airflow
.
models
.



Documentation Source:
docs.astronomer.io/learn/airflow-weaviate.txt

Documentation Title:
Orchestrate Weaviate operations with Apache Airflow | Astronomer Documentation

Documentation Content:
Submit
You can unsubscribe at any time.
By proceeding you agree to our
Privacy Policy
, our
Website Terms
and to receive emails from Astronomer.
Edit this page
Previous
Soda Core
Next
Weights and Biases
Why use Airflow with Weaviate?
Time to complete
Assumed knowledge
Prerequisites
Step 1: Configure your Astro project
Step 2: Add your data
Step 3: Create your DAG
Step 4: Run your DAG
Conclusion
Legal
·
Privacy
·
Security
·
Cookie Preferences
© Astronomer 2023. Various trademarks held by their respective owners.



Documentation Source:
docs.astronomer.io/learn/airflow-database.txt

Documentation Title:
Understanding the Airflow metadata database | Astronomer Documentation

Documentation Content:
environ
[
"USERNAME_AIRFLOW_INSTANCE"
]
password
=
os
.
environ
[
"PASSWORD_AIRFLOW_INSTANCE"
]
# specify which dag to delete
dag_id
=
"dag_to_delete"
# send the deletion request
req
=
requests
.
delete
(
f"
{
ENDPOINT_URL
}
/api/v1/dags/
{
dag_id
}
"
,
auth
=
(
user_name
,
password
)
)
# print the API response
print
(
req
.
text
)
Was this page helpful?
Yes
No
Sign up for Developer Updates
Get a summary of new Astro features once a month.
Submit
You can unsubscribe at any time.
By proceeding you agree to our
Privacy Policy
, our
Website Terms
and to receive emails from Astronomer.
Tags:
Database
SQL
Components
Edit this page
Previous
Executor
Next
Scaling Airflow
Assumed knowledge
Database specifications
Metadata database content
User information (security)
DAG Configurations and Variables (Admin)
DAG and task runs (browse)
Other tables
Airflow metadata database best practices
Use the Airflow REST API to access the metadata database
Retrieve the number of successfully completed tasks
Pause and unpause a DAG
Delete a DAG
Legal
·
Privacy
·
Security
·
Cookie Preferences
© Astronomer 2023. Various trademarks held by their respective owners.



