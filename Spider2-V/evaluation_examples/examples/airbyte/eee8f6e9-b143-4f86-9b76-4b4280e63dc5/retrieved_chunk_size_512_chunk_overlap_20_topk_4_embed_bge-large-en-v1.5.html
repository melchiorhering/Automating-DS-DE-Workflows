Documentation Source:
airbyte.com/tutorials/how-to-use-airflow-and-airbyte-together.html

Documentation Title:
A step-by-step guide to setting up and configuring Airbyte and Airflow to work together | Airbyte

Documentation Content:
For this tutorial I use the following default values:¬†</p><code>BASIC_AUTH_USERNAME=airbyte
BASIC_AUTH_PASSWORD=password
</code><p>Once Airbyte is running, in your browser type in localhost:8000, which should prompt you for a username and password as follows:</p><figcaption>Airbyte OSS¬†login prompt</figcaption><h2>Create a connection</h2><p>Create a connection that sends data from the <strong>Sample Data (Faker)</strong>source to the <strong>Local JSON</strong>(file system) output. Click on ‚ÄúCreate your first connection‚Äù as shown below:</p><figcaption>Create your first connection prompt</figcaption><p>‚Äç</p><p>You should then see an option to set up a source connection. Select the Faker source from the dropdown as shown below.</p><figcaption>Select Sample Data (Faker) as a source</figcaption><p>‚Äç</p><p>After selecting Sample Data as the source, you will see a screen that should look as follows. Click on <strong>Set up source</strong>as shown below.¬†</p><figcaption>Configure Sample Data (Faker) as a source</figcaption><p>‚Äç</p><p>You will then wait a few seconds for the Sample Data source to be verified, at which point you will be prompted to configure the destination that will be used for the connection. Select <strong>Local JSON</strong>as shown below:</p><figcaption>Select Local JSON as a destination</figcaption><p>‚Äç</p><p>After selecting Local JSON as the output, you will need to specify where the JSON files should be written. By default the path that you specify will be located inside <strong>/tmp/airbyte_local</strong>. In this tutorial I set the destination to <strong>/json_from_faker</strong>, which means that the data will be copied to<strong>/tmp/airbyte_local/json_from_faker</strong>on the localhost where Airbyte is running. After specifying the Destination Path, click on Set up destination.



Documentation Source:
airbyte.com/tutorials/building-an-e-commerce-data-pipeline-a-hands-on-guide-to-using-airbyte-dbt-dagster-and-bigquery.html

Documentation Title:
How to build E-commerce Data Pipeline with Airbyte? | Airbyte

Documentation Content:
Here, you should see your source and destination connectors, as well as the connection between them, set up and ready to go üéâ.</p><p>‚Äç</p><figcaption>Airbyte connections</figcaption><h3>Setting Up Airbyte Connectors Using the UI</h3><p>Start by launching the Airbyte UI by going to <a>http://localhost:8000/</a>in your browser. Then:</p><h4>1. Create a source:</h4><ul><li>Go to the Sources tab and click on "+ New source".</li><li>Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".</li><li>Adjust the Count and optional fields as needed for your use case. You can also leave as is.</li><li>Click on "Set up source".</li></ul><figcaption>Look fo Faker source connector</figcaption><figcaption>Create a Faker source</figcaption><h4>2. Create a destination:</h4><ul><li>Go to the Destinations tab and click on "+ New destination".</li><li>Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".</li><li>Enter the connection details as needed.</li><li>For simplicity, you can use "Standard Inserts" as the loading method.</li><li>In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.</li><li>Click on "Set up destination".</li></ul><figcaption>Look for BigQuery destination connector</figcaption><figcaption>Create a BigQuery destination</figcaption><h4>3.



Documentation Source:
airbyte.com/tutorials/how-to-use-airflow-and-airbyte-together.html

Documentation Title:
A step-by-step guide to setting up and configuring Airbyte and Airflow to work together | Airbyte

Documentation Content:
After specifying the Destination Path, click on Set up destination.¬†</p><figcaption>Configure the Local JSON destination</figcaption><p>‚Äç</p><p>This will take you to a page to set up the connection. Set the replication frequency to <strong>Manual</strong>(since we will use Airflow to trigger Airbyte syncs rather than using Airbyte‚Äôs scheduler) and then click on <strong>Set up connection</strong>as highlighted in the image below.</p><figcaption>Specify connection settings</figcaption><p>‚Äç</p><p>Trigger a sync from the <strong>Sample Data (faker)</strong>source to the <strong>Local JSON</strong>output by clicking on <strong>Sync now</strong>as highlighted in the image below.</p><figcaption>Manually trigger a sync from the UI</figcaption><p>‚Äç</p><p>The sync should take a few seconds, at which point you should see that the sync has succeed as shown below.</p><figcaption>After the sync has completed</figcaption><p>‚Äç</p><p>You can now confirm if some sample data has been copied to the expected location. As previously mentioned, for this example the JSON data can be seen in <strong>/tmp/airbyte_local_json_from_faker</strong>. Because there were three streams generated, the following three JSON files should be available:¬†</p><code>_airbyte_raw_products.jsonl	
_airbyte_raw_users.jsonl
_airbyte_raw_purchases.jsonl
</code><p>You have now created a simple example connection in Airbyte which can be manually triggered. A manually triggered connection is ideal for situations where you wish to use an external orchestrator.¬†</p><p>In the next section you will see how to trigger a manual sync on this connection by hitting a REST endpoint directly. After that, you will see how Airflow can be used to hit that same endpoint to trigger synchronizations.¬†</p><h2>Test the API endpoints with cURL</h2><p>Before using the REST endpoint from within Airflow, it is useful to verify that it is working as expected.



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/sources/faker.html

Documentation Title:
Faker | Airbyte Documentation

Documentation Content:
(Yes/No)</th><th>Notes</th></tr><tbody><tr><td>Full Refresh Sync</td><td>Yes</td></tr><tr><td>Incremental Sync</td><td>Yes</td></tr><tr><td>Namespaces</td><td>No</td></tr></tbody></table><p>Of note, if you choose <code>Incremental Sync</code>, state will be maintained between syncs, and once you hit
<code>count</code>records, no new records will be added.</p><p>You can choose a specific <code>seed</code>(integer) as an option for this connector which will guarantee that
the same fake records are generated each time. Otherwise, random data will be created on each
subsequent sync.</p><h3>Requirements<a>‚Äã</a></h3><p>None!</p><h2>Reference<a>‚Äã</a></h2><div><h4>Config fields reference</h4><div><div>Field</div><div>Type</div><div>Property name</div><button><div>‚Ä∫</div><div>Count</div></button><div>integer</div><div>count</div><button><div>‚Ä∫</div><div>Seed</div></button><div>integer</div><div>seed</div><button><div>‚Ä∫</div><div>Records Per Stream Slice</div></button><div>integer</div><div>records_per_slice</div><button><div>‚Ä∫</div><div>Always Updated</div></button><div>boolean</div><div>always_updated</div><button><div>‚Ä∫</div><div>Parallelism</div></button><div>integer</div><div>parallelism</div></div></div><h2>Changelog<a>‚Äã</a></h2><table><tr><th>Version</th><th>Date</th><th>Pull Request</th><th>Subject</th></tr><tbody><tr><td>6.1.0</td><td>2024-04-08</td><a>36898</a><td>Update car prices and years</td></tr><tr><td>6.



