Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/sqlite.txt

Documentation Title:
Sqlite | Airbyte Documentation

Documentation Content:
Access Replicated Data Files
​
If your Airbyte instance is running on the same computer that you are navigating with, you can open your browser and enter
file:///tmp/airbyte_local
to look at the replicated data locally. If the first approach fails or if your Airbyte instance is running on a remote server, follow the following steps to access the replicated files:
Access the scheduler container using
docker exec -it airbyte-server bash
Navigate to the default local mount using
cd /tmp/airbyte_local
Navigate to the replicated file directory you specified when you created the destination, using
cd /{destination_path}
Execute
sqlite3 {filename}
to access the data in a particular database file.
You can also copy the output file to your host machine, the following command will copy the file to the current working directory you are using:
docker cp airbyte-server:/tmp/airbyte_local/{destination_path} .
Note: If you are running Airbyte on Windows with Docker backed by WSL2, you have to use similar step as above or refer to this
link
for an alternative approach.
Changelog
​
Version
Date
Pull Request
Subject
0.1.0
2022-07-25
15018
New SQLite destination
Edit this page
Previous
Snowflake Migration Guide
Next
Starburst Galaxy destination user guide
Overview
Sync Overview
Getting Started
Example:
Access Replicated Data Files
Changelog
Was this page helpful?
Yes
No



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/sqlite.txt

Documentation Title:
Sqlite | Airbyte Documentation

Documentation Content:
1.0
Sqlite
danger
This destination is meant to be used on a local workstation and won't work on Kubernetes
Overview
​
This destination writes data to a file on the
local
filesystem on the host running Airbyte. By default, data is written to
/tmp/airbyte_local
. To change this location, modify the
LOCAL_ROOT
environment variable for Airbyte.
caution
Please make sure that Docker Desktop has access to
/tmp
(and
/private
on a MacOS, as /tmp has a symlink that points to /private. It will not work otherwise). You allow it with "File sharing" in
Settings -> Resources -> File sharing -> add the one or two above folder
and hit the "Apply & restart" button.
Sync Overview
​
Output schema
​
Each stream will be output into its own table
_airbyte_raw_{stream_name}
. Each table will contain 3 columns:
_airbyte_ab_id
: a uuid assigned by Airbyte to each event that is processed.
_airbyte_emitted_at
: a timestamp representing when the event was pulled from the data source.
_airbyte_data
: a json blob representing with the event data.
Features
​
Feature
Supported
Full Refresh Sync
Yes
Incremental - Append Sync
Yes
Incremental - Append + Deduped
No
Namespaces
No
Performance considerations
​
This integration will be constrained by the speed at which your filesystem accepts writes.
Getting Started
​
The
destination_path
will always start with
/local
whether it is specified by the user or not. Any directory nesting within local will be mapped onto the local mount.
By default, the
LOCAL_ROOT
env variable in the
.env
file is set
/tmp/airbyte_local
.
The local mount is mounted by Docker onto
LOCAL_ROOT
. This means the
/local
is substituted by
/tmp/airbyte_local
by default.
Example:
​
If
destination_path
is set to
/local/sqlite.db
the local mount is using the
/tmp/airbyte_local
default
then all data will be written to
/tmp/airbyte_local/sqlite.db
.



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/local-json.txt

Documentation Title:
Local JSON | Airbyte Documentation

Documentation Content:
Access Replicated Data Files
​
If your Airbyte instance is running on the same computer that you are navigating with, you can open your browser and enter
file:///tmp/airbyte_local
to look at the replicated data locally. If the first approach fails or if your Airbyte instance is running on a remote server, follow the following steps to access the replicated files:
Access the scheduler container using
docker exec -it airbyte-server bash
Navigate to the default local mount using
cd /tmp/airbyte_local
Navigate to the replicated file directory you specified when you created the destination, using
cd /{destination_path}
List files containing the replicated data using
ls
Execute
cat {filename}
to display the data in a particular file
You can also copy the output file to your host machine, the following command will copy the file to the current working directory you are using:
docker cp airbyte-server:/tmp/airbyte_local/{destination_path}/{filename}.jsonl .
Note: If you are running Airbyte on Windows with Docker backed by WSL2, you have to use similar step as above or refer to this
link
for an alternative approach.
Changelog
​
Version
Date
Pull Request
Subject
0.2.11
2022-02-14
14641
Include lifecycle management
Edit this page
Previous
Vector Database (powered by LangChain) Migration Guide
Next
Mariadb Columnstore
Overview
Sync Overview
Getting Started
Example:
Access Replicated Data Files
Changelog
Was this page helpful?
Yes
No



Documentation Source:
airbyte.com/docs.airbyte.com/integrations/destinations/csv.txt

Documentation Title:
Local CSV | Airbyte Documentation

Documentation Content:
Access Replicated Data Files
​
If your Airbyte instance is running on the same computer that you are navigating with, you can open your browser and enter
file:///tmp/airbyte_local
to look at the replicated data locally. If the first approach fails or if your Airbyte instance is running on a remote server, follow the following steps to access the replicated files:
Access the scheduler container using
docker exec -it airbyte-server bash
Navigate to the default local mount using
cd /tmp/airbyte_local
Navigate to the replicated file directory you specified when you created the destination, using
cd /{destination_path}
List files containing the replicated data using
ls
Execute
cat {filename}
to display the data in a particular file
You can also copy the output file to your host machine, the following command will copy the file to the current working directory you are using:
docker cp airbyte-server:/tmp/airbyte_local/{destination_path}/{filename}.csv .
Note: If you are running Airbyte on Windows with Docker backed by WSL2, you have to use similar step as above or refer to this
link
for an alternative approach.
Changelog
​
Version
Date
Pull Request
Subject
1.0.0
2022-12-20
17998
Breaking changes: non backwards compatible. Adds delimiter dropdown.
0.2.10
2022-06-20
13932
Merging published connector changes
0.2.9
2022-02-14
10256
Add ExitOnOutOfMemoryError to java connectors and bump versions
0.2.8
2021-07-21
3555
Checkpointing: Partial Success in BufferedStreamConsumer (Destination)
0.2.7
2021-06-09
3973
add AIRBYTE_ENTRYPOINT for kubernetes support
0.2.6
2021-05-25
3290
Checkpointing: Worker use destination (instead of source) for state
0.2.5
2021-05-10
3327
don't split lines on LSEP unicode characters when reading lines in destinations
0.2.4
2021-05-10
3289
bump all destination versions to support outputting messages
0.2.



