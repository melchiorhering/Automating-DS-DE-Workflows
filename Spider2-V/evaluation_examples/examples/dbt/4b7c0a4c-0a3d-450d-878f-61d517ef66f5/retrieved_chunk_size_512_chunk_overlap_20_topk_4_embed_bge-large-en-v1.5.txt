Documentation Source:
docs.getdbt.com/docs/build/sources.txt

Documentation Title:
Add sources to your DAG | dbt Developer Hub

Documentation Content:
This is useful for understanding if your data pipelines are in a healthy state, and is a critical component of defining SLAs for your warehouse.
Declaring source freshness
​
To configure sources to snapshot freshness information, add a
freshness
block to your source and
loaded_at_field
to your table declaration:
models/<filename>.yml
version
:
2
sources
:
-
name
:
jaffle_shop
database
:
raw
freshness
:
# default freshness
warn_after
:
{
count
:
12
,
period
:
hour
}
error_after
:
{
count
:
24
,
period
:
hour
}
loaded_at_field
:
_etl_loaded_at
tables
:
-
name
:
orders
freshness
:
# make this a little more strict
warn_after
:
{
count
:
6
,
period
:
hour
}
error_after
:
{
count
:
12
,
period
:
hour
}
-
name
:
customers
# this will use the freshness defined above
-
name
:
product_skus
freshness
:
null
# do not check freshness for this table
In the
freshness
block, one or both of
warn_after
and
error_after
can be provided. If neither is provided, then dbt will not calculate freshness snapshots for the tables in this source.
Additionally, the
loaded_at_field
is required to calculate freshness for a table. If a
loaded_at_field
is not provided, then dbt will not calculate freshness for the table.
These configs are applied hierarchically, so
freshness
and
loaded_at_field
values specified for a
source
will flow through to all of the
tables
defined in that source. This is useful when all of the tables in a source have the same
loaded_at_field
, as the config can just be specified once in the top-level source definition.
Checking source freshness
​
To snapshot freshness information for your sources, use the
dbt source freshness
command (
reference docs
):
$ dbt source freshness
Behind the scenes, dbt uses the freshness properties to construct a
select
query, shown below. You can find this query in the
query logs
.



Documentation Source:
docs.getdbt.com/reference/resource-properties/freshness.txt

Documentation Title:
freshness | dbt Developer Hub

Documentation Content:
This is particularly useful if:
You are using BigQuery and your source tables are
partitioned tables
You are using Snowflake, Databricks, or Spark with large tables, and this results in a performance benefit
Examples
​
Complete example
​
models/<filename>.yml
version
:
2
sources
:
-
name
:
jaffle_shop
database
:
raw
freshness
:
# default freshness
warn_after
:
{
count
:
12
,
period
:
hour
}
error_after
:
{
count
:
24
,
period
:
hour
}
loaded_at_field
:
_etl_loaded_at
tables
:
-
name
:
customers
# this will use the freshness defined above
-
name
:
orders
freshness
:
# make this a little more strict
warn_after
:
{
count
:
6
,
period
:
hour
}
error_after
:
{
count
:
12
,
period
:
hour
}
# Apply a where clause in the freshness query
filter
:
datediff('day'
,
_etl_loaded_at
,
current_timestamp) < 2
-
name
:
product_skus
freshness
:
# do not check freshness for this table
When running
dbt source freshness
, the following query will be run:
Compiled SQL
Jinja SQL
select
max
(
_etl_loaded_at
)
as
max_loaded_at
,
convert_timezone
(
'UTC'
,
current_timestamp
(
)
)
as
snapshotted_at
from
raw
.
jaffle_shop
.
orders
where
datediff
(
'day'
,
_etl_loaded_at
,
current_timestamp
)
<
2
select
max
(
{{ loaded_at_field }}
)
as
max_loaded_at
,
{{
current_timestamp
(
)
}}
as
snapshotted_at
from
{{ source }}
{
%
if
filter
%
}
where
{{ filter }}
{
%
endif
%
}
Source code
0
Edit this page
Last updated
on
May 16, 2024
Previous
external
Next
identifier
Definition
loaded_at_field
count
period
filter
Examples
Complete example
Edit this page
Terms of Service
Privacy Policy
Security
Cookie Settings
© 2024 dbt Labs, Inc.



Documentation Source:
docs.getdbt.com/docs/deploy/source-freshness.txt

Documentation Title:
Source freshness | dbt Developer Hub

Documentation Content:
You can add source freshness to the list of commands in the job run steps or enable the checkbox. However, you can expect different outcomes when you configure a job by selecting the
Run source freshness
checkbox compared to adding the command to the run steps.
Review the following options and outcomes:
Options
Outcomes
Select checkbox
The
Run source freshness
checkbox in your
Execution Settings
will run
dbt source freshness
as the first step in your job and won't break subsequent steps if it fails. If you wanted your job dedicated
exclusively
to running freshness checks, you still need to include at least one placeholder step, such as
dbt compile
.
Add as a run step
Add the
dbt source freshness
command to a job anywhere in your list of run steps. However, if your source data is out of date
—
this step will "fail", and subsequent steps will not run. dbt Cloud will trigger email notifications (if configured) based on the end state of this step.
You can create a new job to snapshot source freshness.
If you
do not
want your models to run if your source data is out of date, then it could be a good idea to run
dbt source freshness
as the first step in your job. Otherwise, we recommend adding
dbt source freshness
as the last step in the job, or creating a separate job just for this task.
Adding a step to snapshot source freshness
Source freshness snapshot frequency
​
It's important that your freshness jobs run frequently enough to snapshot data latency in accordance with your SLAs. You can imagine that if you have a 1 hour SLA on a particular dataset, snapshotting the freshness of that
table
once daily would not be appropriate. As a good rule of thumb, you should run your source freshness jobs with at least double the frequency of your lowest SLA.  Here's an example table of some reasonable snapshot frequencies given typical SLAs:
SLA
Snapshot Frequency
1 hour
30 mins
1 day
12 hours
1 week
About daily
Further reading
​
Refer to
Artifacts
for more info on how to create dbt Cloud artifacts, share links to the latest documentation, and share source freshness reports with your team.



Documentation Source:
docs.getdbt.com/reference/commands/source.txt

Documentation Title:
About dbt source command | dbt Developer Hub

Documentation Content:
To snapshot freshness for a subset of these sources, use the
--select
flag.
# Snapshot freshness for all Snowplow tables:
$ dbt
source
freshness
--select
"source:snowplow"
# Snapshot freshness for a particular source table:
$ dbt
source
freshness
--select
"source:snowplow.event"
Configuring source freshness output
​
When
dbt source freshness
completes, a
JSON
file containing information about the freshness of your sources will be saved to
target/sources.json
. An example
sources.json
will look like:
target/sources.json
{
"meta"
:
{
"generated_at"
:
"2019-02-15T00:53:03.971126Z"
,
"elapsed_time"
:
0.21452808380126953
}
,
"sources"
:
{
"source.project_name.source_name.table_name"
:
{
"max_loaded_at"
:
"2019-02-15T00:45:13.572836+00:00Z"
,
"snapshotted_at"
:
"2019-02-15T00:53:03.880509+00:00Z"
,
"max_loaded_at_time_ago_in_s"
:
481.307673
,
"state"
:
"pass"
,
"criteria"
:
{
"warn_after"
:
{
"count"
:
12
,
"period"
:
"hour"
}
,
"error_after"
:
{
"count"
:
1
,
"period"
:
"day"
}
}
}
}
}
To override the destination for this
sources.json
file, use the
-o
(or
--output
) flag:
# Output source freshness info to a different path
$ dbt source freshness --output target/source_freshness.json
Using source freshness
​
Snapshots of source freshness can be used to understand:
If a specific data source is in a delayed state
The trend of data source freshness over time
This command can be run manually to determine the state of your source data freshness at any time. It is also recommended that you run this command on a schedule, storing the results of the freshness snapshot at regular intervals.



