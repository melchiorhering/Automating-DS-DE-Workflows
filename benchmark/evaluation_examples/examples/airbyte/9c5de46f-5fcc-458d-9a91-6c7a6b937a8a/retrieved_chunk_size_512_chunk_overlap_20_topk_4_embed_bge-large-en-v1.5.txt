Documentation Source:
airbyte.com/tutorials/building-an-e-commerce-data-pipeline-a-hands-on-guide-to-using-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
How to build E-commerce Data Pipeline with Airbyte? | Airbyte

Documentation Content:
Create a source:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
Look fo Faker source connector
Create a Faker source
2. Create a destination:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
Look for BigQuery destination connector
Create a BigQuery destination
3. Create a connection:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
For this project, leave the ‚Äúreplication frequency‚Äù as ‚ÄúManual‚Äù, since we will orchestrate the syncs with Dagster.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
‚Äç
Establish a connector between Faker and BigQuery
4. Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery.
1. Navigate to the dbt Project Directory:
Move to the dbt project directory in your project's file structure.
cd ../../dbt_project
This directory contains all the dbt-related configurations and SQL models.
2. Update Connection Details:
Within this directory, you'll find a <span class="text-style-code">profiles.yml file</span>. This file holds the configuration for dbt to connect to BigQuery.



Documentation Source:
airbyte.com/docs.airbyte.com/using-airbyte/getting-started/add-a-source.txt

Documentation Title:
Add a Source | Airbyte Documentation

Documentation Content:
Add a Source | Airbyte Documentation
Skip to main content
About Airbyte
Tutorials
Support
Cloud Status
Try Airbyte Cloud
Search
Airbyte Connectors
Connector Catalog
Build a Connector
Connector Support Levels
Using Airbyte
Getting Started
Core Concepts
Add a Source
Add a Destination
Set up a Connection
Configuring Connections
Managing Syncs
Managing Airbyte
Deploy Airbyte
Self-Managed Enterprise
Upgrading Airbyte
Configuring Airbyte
Access Management
Airbyte at Scale
Security
Integrating with Airbyte
Account Management
Developer Guides
API documentation
Terraform Documentation
Using PyAirbyte
Understand Airbyte
Contribute to Airbyte
Licenses
Community
Getting Support
Code of Conduct
Product Updates
Roadmap
Release Notes
Getting Started
Add a Source
Add a Source
Available
Cloud
Available
Self-Managed Community (OSS)
Available
Self-Managed Enterprise
Setting up a new source in Airbyte is a quick and simple process! When viewing the Airbyte UI, you'll see the main navigation bar on the left side of your screen. Click the
Sources
tab to bring up a list of all available sources.
You can use the provided search bar, or simply scroll down the list to find the source you want to replicate data from. Let's use a demo source, Faker, as an example. Clicking on the
Sample Data (Faker)
card will bring us to its setup page.
The left half of the page contains a set of fields that you will have to fill out. In the
Source name
field, you can enter a name of your choosing to help you identify this instance of the connector. By default, this will be set to the name of the source (ie,
Sample Data (Faker)
).
Each connector in Airbyte will have its own set of authentication methods and configurable parameters. In the case of Sample Data (Faker), you can adjust the number of records you want returned in your
Users
data, and optionally adjust additional configuration settings. You can always refer to your source's provided setup guide for specific instructions on filling out each field.
info
Some sources will have an
Optional Fields
tab.



Documentation Source:
airbyte.com/quickstart/airbyte-dbt-and-airflow-stack-with-bigquery.txt

Documentation Title:
E-commerce Analytics Stack with Airbyte, dbt, Airflow (ADA) and BigQuery | Airbyte

Documentation Content:
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
2. Create a destination
:
Go to the "Destinations" tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select BigQuery.
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the Service Account Key JSON field, enter the contents of the JSON file. Yes, the full JSON.
Click on Set up destination.
3. Create a connection
:
Go to the "Connections" tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
4. Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery. Here‚Äôs a step-by-step guide to help you set this up:
1. Navigate to the dbt Project Directory
:
Move to the directory containing the dbt configuration:
cd ../../dbt_project
‚Äç
2. Update Connection Details
:
You'll find a <span class="text-style-code">profiles.yml</span> file within the directory. This file contains configurations for dbt to connect with your data platform.
Update this file with your BigQuery connection details. Specifically, you need to update the Service Account JSON file path, the dataset location and your BigQuery project ID.
Provide your BigQuery project ID in the database field of the <span class="text-style-code">/models/ecommerce/sources/faker_sources.yml</span> file.
3. Test the Connection (Optional)
:
You can test the connection to your BigQuery instance using the following command.



Documentation Source:
airbyte.com/quickstart/e-commerce-analytics-with-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
E-commerce Analytics Stack with Airbyte, dbt, Dagster and BigQuery | Airbyte

Documentation Content:
Setting Up Airbyte Connectors Using the UI
Start by launching the Airbyte UI by going to
http://localhost:8000/
in your browser. Then:
1. Create a source
:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
2. Create a destination
:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
3. Create a connection
:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery. Here‚Äôs a step-by-step guide to help you set this up:
1. Navigate to the dbt Project Directory
:
Move to the directory containing the dbt configuration:
cd ../../dbt_project
2. Update Connection Details
:
You'll find a <span class="text-style-code">profiles.yml</span> file within the directory. This file contains configurations for dbt to connect with your data platform. Update this file with your BigQuery connection details. Specifically, you need to update the Service Account JSON file path and your BigQuery project ID.
Provide your BigQuery project ID in the database field of the <span class="text-style-code">dbt_project/models/sources/faker_sources.yml</span> file.



