Documentation Source:
docs.astronomer.io/learn/testing-airflow.html

Documentation Title:
Test Airflow DAGs | Astronomer Documentation

Documentation Content:
</span><span>tasks</span><span>,</span><span>f"</span><span>{</span><span>dag_id</span><span>}</span><span>in </span><span>{</span><span>fileloc</span><span>}</span><span>has no tasks"</span></span><span><span>for</span><span>task </span><span>in</span><span>dag</span><span>.</span><span>tasks</span><span>:</span></span><span><span>t_rule </span><span>=</span><span>task</span><span>.</span><span>trigger_rule</span></span><span><span>assert</span><span>(</span></span><span><span>t_rule </span><span>==</span><span>"all_success"</span></span><span><span>)</span><span>,</span><span>f"</span><span>{</span><span>task</span><span>}</span><span>in </span><span>{</span><span>dag_id</span><span>}</span><span>has the trigger rule </span><span>{</span><span>t_rule</span><span>}</span><span>"</span></span></code><h2>Implement DAG validation tests<a>​</a></h2><p>Airflow offers different ways to run DAG validation tests using any Python test runner. This section gives an overview of the most common implementation methods. If you are new to testing Airflow DAGs, you can quickly get started by using Astro CLI commands.</p><h3>Airflow CLI<a>​</a></h3><p>The Airflow CLI offers two commands related to local testing:</p><ul><li><code>airflow dags test</code>: Given a DAG ID and execution date, this command writes the results of a single DAG run to the metadata database.



Documentation Source:
docs.astronomer.io/learn/debugging-dags.html

Documentation Title:
Debug DAGs | Astronomer Documentation

Documentation Content:
A DAG with a <code>start_date</code>in the future will result in a successful DAG run with no task runs. Do not use <code>datetime.now()</code>as a <code>start_date</code>.</p><p>Test the DAG using <code>astro dev dags test &lt;dag_id&gt;</code>. With the Airflow CLI, run <code>airflow dags test &lt;dag_id&gt;</code>.</p><p>If no DAGs are running, check the state of your scheduler
using <code>astro dev logs -s</code>.</p><p>If too many runs of your DAG are being scheduled after you unpause it, you most likely need to set <code>catchup=False</code>in your DAG's parameters.</p></ul><p>If your DAG is running, but not on the schedule you expected, review the <a>DAG Schedule DAGs in Airflow</a>guide. If you are using a custom timetable, ensure that the data interval for your DAG run does not precede the DAG start date.</p><h2>Common task issues<a>​</a></h2><p>This section covers common issues related to individual tasks you might encounter. If your entire DAG is not working, see the <a>DAGs are not running correctly</a>section above.</p><h3>Tasks are not running correctly<a>​</a></h3><p>It is possible for a DAG to start but its tasks to be stuck in various states or to not run in the desired order. If your tasks are not running as intended, try the following debugging methods:</p><ul><li>Double check that your DAG's <code>start_date</code>is in the past. A future <code>start_date</code>will result in a successful DAG run even though no tasks ran.</li><li>If your tasks stay in a <code>scheduled</code>or <code>queued</code>state, ensure your scheduler is running properly.



Documentation Source:
docs.astronomer.io/learn/testing-airflow.html

Documentation Title:
Test Airflow DAGs | Astronomer Documentation

Documentation Content:
Unlike using the base <code>airflow</code>package, this testing method requires starting up a complete Airflow environment.</p><h3>Use variables and connections in dag.test()<a>​</a></h3><p>To debug your DAGs in a more realistic environment, you can pass the following Airflow environment configurations to <code>dag.test()</code>:</p><ul><li><code>execution_date</code>passed as a <code>pendulum.datetime</code>object.</li><li><a>Airflow connections</a>passed as a <code>.yaml</code>file.</li><li>Airflow variables passed as a <code>.yaml</code>file.</li><li>DAG configuration passed as a dictionary.</li></ul><p>This is useful for testing your DAG for different dates or with different connections and configurations. The following code snippet shows the syntax for passing various parameters to <code>dag.test()</code>:</p><code><span><span>from</span><span>pendulum </span><span>import</span><span>datetime </span></span><span><span>if</span><span>__name__ </span><span>==</span><span>"__main__"</span><span>:</span></span><span><span>conn_path </span><span>=</span><span>"connections.yaml"</span></span><span><span>variables_path </span><span>=</span><span>"variables.yaml"</span></span><span><span>my_conf_var </span><span>=</span><span>23</span></span><span><span>dag</span><span>.</span><span>test</span><span>(</span></span><span><span>execution_date</span><span>=</span><span>datetime</span><span>(</span><span>2023</span><span>,</span><span>1</span><span>,</span><span>29</span><span>)</span><span>,</span></span><span><span>conn_file_path</span><span>=</span><span>conn_path</span><span>,



Documentation Source:
docs.astronomer.io/learn/testing-airflow.html

Documentation Title:
Test Airflow DAGs | Astronomer Documentation

Documentation Content:
Therefore, you don't need to specify them in <code>.airflowignore</code>to prevent parsing.</p><p>If you're running Airflow locally, apply your changes by refreshing the Airflow UI.</p><h2>Debug interactively with dag.test()<a>​</a></h2><p>The <code>dag.test()</code>method allows you to run all tasks in a DAG within a single serialized Python process, without running the Airflow scheduler. The <code>dag.test()</code>method lets you iterate faster and use IDE debugging tools when developing DAGs.</p><p>This functionality replaces the deprecated DebugExecutor. Learn more in the <a>Airflow documentation</a>.</p><h3>Prerequisites<a>​</a></h3><p>Ensure that your testing environment has:</p><ul><li><a>Airflow 2.5.0</a>or later. You can check your version by running <code>airflow version</code>.</li><li>All provider packages that your DAG uses.</li><li>An initialized <a>Airflow metadata database</a>, if your DAG uses elements of the metadata database like XCom. The Airflow metadata database is created when Airflow is first run in an environment. You can check that it exists with <code>airflow db check</code>and initialize a new database with <code>airflow db migrate</code>(<code>airflow db init</code>in Airflow versions pre-2.7).</li></ul><p>You may wish to install these requirements and test your DAGs in a <a>virtualenv</a>to avoid dependency conflicts in your local environment.</p><h3>Setup<a>​</a></h3><p>To use <code>dag.test()</code>, you only need to add a few lines of code to the end of your DAG file. If you are using a traditional DAG context, call <code>dag.test()</code>after your DAG declaration. If you are using the <code>@dag</code>decorator, assign your DAG function to a new object and call the method on that object.



