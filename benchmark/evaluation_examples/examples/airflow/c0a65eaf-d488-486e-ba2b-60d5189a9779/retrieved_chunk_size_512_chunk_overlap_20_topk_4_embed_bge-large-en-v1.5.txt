Documentation Source:
docs.astronomer.io/astro/cloud-ide/quickstart.txt

Documentation Title:
Astro Cloud IDE quickstart | Astronomer Documentation

Documentation Content:
Click
Results
to view the result of your successful cell run.
info
If the error message
Could not connect to cell execution environment
appears after running a cell, check the
Astro status page
to determine the operational status of the Astro control plane. If the control plane is operational, contact
Astronomer support
and share the error. To enable cell runs, Astronomer support might need to set up additional cloud infrastructure for the IDE.
Step 5: Create a database connection
​
To create a SQL cell and execute SQL, first create a database to run your SQL queries against.
Click the
Connections
tab and then click
Connection
.
Click
NEW CONNECTION
.
Choose one of the available connection types and configure all required values for the connection. Click
More options
to configure optional values for the connection.
info
SQL cell query results are stored in XComs and are not accessible outside of your data pipeline. To save the results of a SQL query, run it in a SQL warehouse cell. See
Run SQL
.
Optional. Click
Test Connection
. The Astro Cloud IDE runs a quick connection test and returns a status message. You can still create the connection if the test is unsuccessful.
Click
Create Connection
. You new connection appears in the
Connections
tab both in the pipeline editor and on your project homepage. You can use this connection with any future pipelines you create in this project.
Step 6: Create a SQL cell
​
You can now write and run SQL cells with your database connection.
In the
Pipeline
list, click the name of the pipeline you created in step 2.
Click
Add Cell
and select
SQL
. A new cell named
sql_1
appears.
Click the cell name and rename it
hello_sql
.
In the
Select Connection
list, select the connection you created in step 5.
Add the following code to the cell:
SELECT
1
AS
hello_world
;
tip
You can also add a SQL cell with a specific connection by clicking the
+
button from the
Connections
tab in the
Environment
menu.
Optional. Click
Run
to test the SQL query.



Documentation Source:
docs.astronomer.io/learn/airflow-sql-data-quality.txt

Documentation Title:
Run data quality checks using SQL check operators | Astronomer Documentation

Documentation Content:
See
Data quality and Airflow
.
Running SQL from Airflow. See
Using Airflow to execute SQL
.
Prerequisites
​
The
Astro CLI
.
Access to a relational database. You can use an in-memory SQLite database for which you'll need to install the
SQLite provider
. Note that currently the operators cannot support BigQuery
job_id
s.
A love for birds.
Step 1: Configure your Astro project
​
To use SQL check operators, install the
Common SQL provider
in your Astro project.
Run the following commands to create a new Astro project:
$
mkdir
astro-sql-check-tutorial
&&
cd
astro-sql-check-tutorial
$ astro dev init
Add the Common SQL provider and the SQLite provider to your Astro project
requirements.txt
file.
apache-airflow-providers-common-sql==1.5.2
apache-airflow-providers-sqlite==3.4.2
Step 2: Create a connection to SQLite
​
In the Airflow UI, go to
Admin
>
Connections
and click
+
.
Create a new connection named
sqlite_conn
and choose the
SQLite
connection type. Enter the following information:
Connection Id
:
sqlite_conn
.
Connection Type
:
SQLite
.
Host
:
/tmp/sqlite.db
.
Step 3: Add a SQL file with a custom check
​
In your
include
folder, create a file called
custom_check.sql
.
Copy and paste the following SQL statement into the file:
WITH
all_combinations_unique
AS
(
SELECT
DISTINCT
bird_name
,
observation_year
AS
combos_unique
FROM
'{{ params.table_name }}'
)
SELECT
CASE
WHEN
COUNT
(
*
)
=
COUNT
(
combos_unique
)
THEN
1
ELSE
0
END
AS
is_unique
FROM
'{{ params.table_name }}'
JOIN
all_combinations_unique
;
This SQL statement returns 1 if all combinations of
bird_name
and
observation_year
in a templated table are unique, and 0 if not.
Step 4: Create a DAG using SQL check operators
​
Start Airflow by running
astro dev start
.



Documentation Source:
docs.astronomer.io/learn/airflow-sql-data-quality.txt

Documentation Title:
Run data quality checks using SQL check operators | Astronomer Documentation

Documentation Content:
Create a new file in your
dags
folder called
sql_data_quality.py
.
Copy and paste the following DAG code into the file:
"""
## Check data quality using SQL check operators
This DAG creates a toy table about birds in SQLite to run data quality checks on using the
SQLColumnCheckOperator, SQLTableCheckOperator, and SQLCheckOperator.
"""
from
airflow
.
decorators
import
dag
from
airflow
.
providers
.
common
.
sql
.
operators
.
sql
import
(
SQLColumnCheckOperator
,
SQLTableCheckOperator
,
SQLCheckOperator
,
)
from
airflow
.
providers
.
sqlite
.
operators
.
sqlite
import
SqliteOperator
from
pendulum
import
datetime
_CONN_ID
=
"sqlite_conn"
_TABLE_NAME
=
"birds"
@dag
(
start_date
=
datetime
(
2023
,
7
,
1
)
,
schedule
=
None
,
catchup
=
False
,
template_searchpath
=
[
"/usr/local/airflow/include/"
]
,
)
def
sql_data_quality
(
)
:
create_table
=
SqliteOperator
(
task_id
=
"create_table"
,
sqlite_conn_id
=
_CONN_ID
,
sql
=
f"""
CREATE TABLE IF NOT EXISTS
{
_TABLE_NAME
}
(
bird_name VARCHAR,
observation_year INT,
bird_happiness INT
);
"""
,
)
populate_data
=
SqliteOperator
(
task_id
=
"populate_data"
,
sqlite_conn_id
=
_CONN_ID
,
sql
=
f"""
INSERT INTO
{
_TABLE_NAME
}
(bird_name, observation_year, bird_happiness) VALUES
('King vulture (Sarcoramphus papa)', 2022, 9),
('Victoria Crowned Pigeon (Goura victoria)', 2021, 10),
('Orange-bellied parrot (Neophema chrysogaster)', 2021, 9),
('Orange-bellied parrot (Neophema chrysogaster)', 2020, 8),
(NULL, 2019, 8),



Documentation Source:
docs.astronomer.io/astro/cloud-ide/configure-project-environment.txt

Documentation Title:
Configure your Astro Cloud IDE project environment | Astronomer Documentation

Documentation Content:
You can then reference the connection in your Python cells as code or in SQL cells as a configuration.
In the Astro UI, select a Workspace and then select
Cloud IDE
.
Select a project.
Click the
Connections
tab, and then click
Connection
.
Select a connection type.
Configure the connection.
Optional. Click
Test connection
to check that you configured the connection correctly. Note that you cannot test generic connections.
Click
Create Connection
.
The connection appears in the
Connections
list. To edit the connection, click
Edit
in the
Connections
list.
Use connections in cells
​
To use a connection in a Python cell, pass the connection ID to any function that accepts an Airflow connection as an argument, such as a
hook
.
To use a connection in a SQL or Warehouse SQL cell:
In the Astro UI, select a Workspace and then select
Cloud IDE
.
Select a project.
Click the
Pipelines
tab, and then click a pipeline name to open the pipeline editor.
In a SQL or Warehouse SQL cell, click
Select connection
and select the connection you want to use to store the results of the cell. If you are configuring a Warehouse SQL cell, additionally configure the
Output Table
where you want to permanently store the results of the cell query.
Optional. Call a table from your database in your SQL query. For example:
SELECT
*
FROM
table_name
;
View environment configurations from the pipeline editor
​
Environment configurations apply to all pipelines in a project. To view your configurations in the pipeline editor, click
Environment
. The
Use in your pipeline
pane shows all configurations that apply to your current pipeline. You can add, delete, or modify environment configurations in the pane.
info
Environment configurations exist at the project level. Modifying them in your pipeline editor updates the configurations for all pipelines in your project. To run a data pipeline with different environment configurations from its existing IDE project, you must recreate it in a new IDE project.
Was this page helpful?
Yes
No
Sign up for Developer Updates
Get a summary of new Astro features once a month.
Submit
You can unsubscribe at any time.



