{
    "id": "ffe6c342-0511-4dff-aeed-e53d87125961",
    "snapshot": "airflow",
    "instruction": "I am using Astronomer to deploy Airflow. Now, I would like to connect to sqlite and try creating a customed SQL check, details of which can be found in the README.md. Please create connection, finish the DAG file sql_data_quality and custom_check.sql, restart, trigger the dag, download the log file of Checker task you have finished and rename it accordingly by the task_id for me to check the quality of the data. Click Download in the detail screen of corresponding task instance of your run on astronomer web-ui to download log file. \nHere is a step-by-step tutorial from an expert instructing you how to complete it:\nI am using Astronomer to deploy Airflow\nTo build a connection on Airflow, create customed checker to check sql data quality and trigger the dag, we can follow the steps:\n1. Click the VS Code editor on the left panel or dock;\n2. According to the opened README.md file, we can extract the basic information about the connection; \n3. Now, click the Chromium on the left panel to switch to the opened airflow web page;\n4. Click the \"Admin\" button in the top menu bar of the web page;\n5. Select \"Connections\" from the drop-down menu;\n6. In the new page, click the blue button \"+\" below the search bar to create new Connection;\n7. In the window \"Add Connection\", firstly set the category to \"SQLite\";\n8. Next, type in values from config.yaml into the corresponding fields in the form:\n   Connection id: sqlite_conn, \n   Host: '/tmp/sqlite.db'\n9. After filling these fields, click the button \"Save\" at the bottom of the web page;\n10. Then, we will see a new line with name \"sqlite_conn\" in the connection panel;\n11. After the Connection build is completed, click the VS Code editor on the left panel or dock; \n12. According to the opened README.md file, we can extract the instructions on completing the DAG file;\n13. Switch to the sql file 'custom_check.sql' that is opened in VSCode;\n14. We'll now define a customed SQL operation. Concretely, we'll calculate and compare the average \"bird_happiness\" value before and after 2019:\nˋˋˋ\n# ... Keep the original ˋcustom_checkˋ codes\n\nWITH happiness_data AS (\n  SELECT\n    AVG(CASE WHEN observation_year >= 2019 THEN bird_happiness END) AS avg_happiness_post_2019,\n    AVG(CASE WHEN observation_year < 2019 THEN bird_happiness END) AS avg_happiness_pre_2019\n  FROM '{{ params.table_name }}'\n)\nSELECT CASE\n  WHEN avg_happiness_post_2019 < avg_happiness_pre_2019 THEN 1\n  ELSE 0\nEND AS happiness_comparison\nFROM '{{ params.table_name }}' JOIN happiness_data;\nˋˋˋ\n15. Save the file content, then swith to the \"sql_data_quality.py\" that is opened in VSCode. We'll now define a SQLCheckOperator:\nˋˋˋ\n# ... Keep the original ˋsql_data_qualityˋ codes\n\ncustom_happy_check = SQLCheckOperator(\n    task_id=\"custom_happiness_check\",\n    conn_id=_CONN_ID,\n    sql=\"custom_check.sql\",\n    params={\"table_name\": _TABLE_NAME},\n)\nˋˋˋ\n16. Save the file content and switch to the opened ‘/home/user/projects/SQL_Check’ terminal.\n17. In the terminal, type in the following command to restart the UI:\n`astro dev restart` \n18. Click the Chromium on the left pannel\n19. On the Airflow web page, find \"sql_data_quality\" in the DAG list and click the slider to the left of the name to Unpause dag; \n20. Click the triangle under the Action column on the far right of the row to trigger the dag; \n21. Wait until the status of all tasks in the 'Runs' column to change to \"success\" or \"failed\";\n22. Click sql_data_quality in the Dag column to enter task details page of the dag;\n23. In the dag details page, click the rightmost box in the custom_happy_check task row under the histogram on the left side of the UI to enter the corresponding task instance;\n24. Click logs in the details row on the right to enter the log page;\n25. Click Download above the log content box to download the log; \n26. Switch to the opened ‘/home/user/Downloads’ terminal, type in the following command to get the file list:\n`ls` \n27. Then, type in the following command  to rename the log file containing custom_happy_check in their file names to custom_happy_check.log respectively:\n`mv \"old_name\" \"new_name\"`\nYou can exactly follow the detailed plan above or proactively tackle the task based on the real-time environment interaction by yourself.",
    "source": [
        "https://docs.astronomer.io/learn/airflow-sql-data-quality"
    ],
    "config": [
        {
            "type": "copyfile_from_host_to_guest",
            "parameters": {
                "src": "evaluation_examples/examples/airflow/ffe6c342-0511-4dff-aeed-e53d87125961/SQL_Check.zip",
                "dest": "/home/user/SQL_Check.zip"
            }
        },
        {
            "type": "script_and_execute",
            "parameters": {
                "src": "evaluation_examples/examples/airflow/ffe6c342-0511-4dff-aeed-e53d87125961/init.sh",
                "dest": "/home/user/init.sh"
            }
        },
        {
            "type": "google_chrome_browser",
            "parameters": {
                "debugging_port": 1337,
                "listening_port": 9222,
                "urls": [
                    "https://www.bing.com/"
                ]
            }
        },
        {
            "type": "astro_webui_init",
            "parameters": {
                "listening_port": 9222,
                "url": "http://localhost:8080",
                "actions": [
                    {
                        "type": "login",
                        "username": "admin",
                        "password": "admin"
                    }
                ]
            }
        }
    ],
    "action_number": 27,
    "related_apps": [
        "airflow",
        "chromium",
        "terminal",
        "vscode"
    ],
    "tags": [
        "cli+gui",
        "data_orchestration",
        "verbose"
    ],
    "evaluator": {
        "func": "check_include_exclude",
        "result": {
            "type": "vm_script_output",
            "src": "evaluation_examples/examples/airflow/ffe6c342-0511-4dff-aeed-e53d87125961/eval.sh",
            "dest": "/home/user/eval.sh"
        },
        "expected": {
            "type": "rule",
            "rules": {
                "include": [
                    "succeed"
                ],
                "exclude": [
                    "failed"
                ]
            }
        }
    },
    "counterpart": "eba58e80-a10f-4698-b714-e736dc5b0f62"
}