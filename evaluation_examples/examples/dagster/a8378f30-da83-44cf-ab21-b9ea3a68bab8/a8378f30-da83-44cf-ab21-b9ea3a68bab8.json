{
    "id": "a8378f30-da83-44cf-ab21-b9ea3a68bab8",
    "snapshot": "dagster",
    "instruction": "I have created an asset to download the top 10 story ids in the opened project. Could you help me extend it into a pipeline `top10_story_ids -> top10_stories -> top5_mfw`, which further downloads the list of these 10 stories into data/stories.json and calculates top 5 most frequent words in titles into data/mfw.json (dict with format word: count)? Oh, please exclude words in stopwords.txt during counting. For splitting text into words, just use the basic text.split() method and ignore case.\nHere is a step-by-step tutorial from an expert instructing you how to complete it:\nIn this task, we want to extend the original single Dagster asset into a 3-step pipeline graph `top10_story_ids -> top10_stories -> top5_mfw`. Please follow the steps below:\n1. Click the VS Code editor on the left panel or dock;\n2. In the opened `assets.py` file, it defines one asset `top10_story_ids` to download the top 10 story ids into filepath `data/story_ids.json`;\n3. Using the top 10 Hacker News story IDs, we'll now look up each story by its ID, ingest that data, and make a DataFrame out of it. Besides, we will connect the current asset `top10_story_ids` with this new asset `top10_stories` to establish dependencies. Concretely, we modify the `assets.py` to add the pandas import and a new asset called `top10_stories`:\n```\n# ... Keep the original `top10_story_ids` code\n\n@asset(deps=[top10_story_ids])  # this asset is dependent on top10_story_ids\ndef top10_stories() -> None:\n    with open(\"data/story_ids.json\", \"r\") as f:\n        story_ids = json.load(f)\n\n    results = []\n    for item_id in story_ids:\n        item = requests.get(\n            f\"https://hacker-news.firebaseio.com/v0/item/{item_id}.json\"\n        ).json()\n        results.append(item)\n\n        if len(results) % 5 == 0:\n            print(f\"Got {len(results)} items so far.\")\n\n    json.dump(results, open('data/stories.json', 'w'), indent=4, ensure_ascii=False)\n```\n4. Now, we have extend the original asset to a 2-step pipeline, which not only downloads the story id, but also the story itself. The final asset will take the list of stories and create a dictionary of the most frequent words in the titles. Here is the finished code for the `top5_mfw` asset. Copy and paste the code into `assets.py`:\n```\n@asset(deps=[top10_stories])\ndef top5_mfw() -> None:\n    stopwords = []\n    with open('stopwords.txt', 'r') as inf:\n        for line in inf:\n            line = line.strip()\n            if line == '': continue\n            stopwords.append(line)\n\n    topstories = json.load(open('data/stories.json', 'r'))\n\n    # loop through the titles and count the frequency of each word\n    word_counts = {}\n    for story in topstories:\n        raw_title = story['title']\n        title = raw_title.lower()\n        for word in title.split():\n            if word not in stopwords and len(word) > 0:\n                word_counts[word] = word_counts.get(word, 0) + 1\n\n    # Get the top 5 most frequent words\n    top_words = {\n        pair[0]: pair[1]\n        for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n    }\n\n    with open(\"data/mfw.json\", \"w\") as f:\n        json.dump(top_words, f)\n```\n5. Next, save the file content and switch to the web browser;\n6. Click \"Reload definitions\" on the top right to update all assets;\n7. Click the \"Assets\" panel on the top menu. We can see that the other two new assets have never been materialized;\n8. Switch to the graph view by clicking \"View global asset lineage\" on the left side of \"Reload definitions\";\n9. Finally, click the magic button \"Materialize all\" and waiting for all assets to be materialized.\nYou can exactly follow the detailed plan above or proactively tackle the task based on the real-time environment interaction by yourself.",
    "source": [
        "https://docs.dagster.io/tutorial/writing-your-first-asset"
    ],
    "related_apps": [
        "chromium",
        "vscode",
        "dagster"
    ],
    "tags": [
        "cli+gui",
        "data_orchestration",
        "verbose"
    ],
    "action_number": 9,
    "config": [
        {
            "type": "copyfile_from_host_to_guest",
            "parameters": {
                "src": "evaluation_examples/examples/dagster/a8378f30-da83-44cf-ab21-b9ea3a68bab8/hacker_news.zip",
                "dest": "/home/user/hacker_news.zip"
            }
        },
        {
            "type": "script_and_execute",
            "parameters": {
                "src": "evaluation_examples/examples/dagster/a8378f30-da83-44cf-ab21-b9ea3a68bab8/init.sh",
                "dest": "/home/user/init.sh"
            }
        },
        {
            "type": "google_chrome_browser",
            "parameters": {
                "debugging_port": 1337,
                "listening_port": 9222,
                "urls": [
                    "https://www.bing.com/"
                ]
            }
        },
        {
            "type": "dagster_webui_init",
            "parameters": {
                "listening_port": 9222,
                "url": "http://localhost:3000",
                "actions": [
                    {
                        "type": "close_popups"
                    },
                    {
                        "type": "materialize_assets"
                    }
                ]
            }
        }
    ],
    "evaluator": {
        "postconfig": [
            {
                "type": "copyfile_from_host_to_guest",
                "parameters": {
                    "src": "evaluation_examples/examples/dagster/a8378f30-da83-44cf-ab21-b9ea3a68bab8/golden_hacker_news.zip",
                    "dest": "/home/user/hacker_news.zip"
                }
            }
        ],
        "func": [
            "check_include_exclude",
            "compare_json_file",
            "compare_json_file"
        ],
        "result": [
            {
                "type": "vm_script_output",
                "src": "evaluation_examples/examples/dagster/a8378f30-da83-44cf-ab21-b9ea3a68bab8/eval.sh",
                "dest": "/home/user/eval.sh"
            },
            {
                "type": "vm_file",
                "path": "/home/user/projects/hacker_news/data/stories.json",
                "dest": "stories.json"
            },
            {
                "type": "vm_file",
                "path": "/home/user/projects/hacker_news/data/mfw.json",
                "dest": "mfw.json"
            }
        ],
        "expected": [
            {
                "type": "rule",
                "rules": {
                    "include": [
                        "succeed"
                    ],
                    "exclude": [
                        "failed"
                    ]
                }
            },
            {
                "type": "vm_file",
                "path": "/home/user/hacker_news/data/stories.json",
                "dest": "golden_stories.json"
            },
            {
                "type": "vm_file",
                "path": "/home/user/hacker_news/data/mfw.json",
                "dest": "golden_mfw.json"
            }
        ]
    },
    "counterpart": "5fee7fff-5745-462a-a289-7d10346111fe"
}