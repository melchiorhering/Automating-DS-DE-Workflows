{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Preprocessing California Housing Dataset with Feature Scaling",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We are going to use the California housing dataset to illustrate how data scaling works. The dataset was derived from the 1990 U.S. census. One row of the dataset represents the census of one block group.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Import and Load the Dataset",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import fetch_california_housing\n\ncalifornia_housing = fetch_california_housing(as_frame=True)\ndf = california_housing.frame",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Explore the Dataset",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Take a peak at the first few rows of data. Help me use appropriate function to display first few rows of data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# TODO1: Use appropriate function to display first few rows of data\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Preprocessing the Dataset",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We need to predict another median house value. To do so, we will assign ``MedHouseVal`` to ``y`` and all other columns to ``X`` just by dropping ``MedHouseVal``.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y = df['MedHouseVal']\nX = df.drop(['MedHouseVal'], axis = 1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Splitting Data into Train and Test Sets",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Help me finish this part. You should sample 75% of the data for training and 25% of the data for testing. To ensure a reproducible evaluation, set the random_state using the provided ``SEED``.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nSEED = 42\n# TODO2: use train_test_split to split the train and test sets\n\n\n# Inspect those numbers quickly by printing the lengths of the full dataset and of split data\nlen(X)\nlen(X_train)\nlen(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Feature Scaling both Train and Test Sets",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "By importing StandardScaler, instantiating it, fitting it according to our train data (preventing leakage), and transforming both train and test datasets, we can perform feature scaling. Help me finish this part.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n\n# TODO3: apply feature scaling.\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's organize the data into a ``DataFrame`` again with column names and use describe() to observe the changes in mean and std.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "col_names=['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\nscaled_df = pd.DataFrame(X_train, columns=col_names)\nscaled_df.describe().T",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}