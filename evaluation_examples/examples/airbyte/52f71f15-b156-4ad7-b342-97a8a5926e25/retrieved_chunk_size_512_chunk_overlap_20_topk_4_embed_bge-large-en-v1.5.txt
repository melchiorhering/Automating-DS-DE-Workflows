Documentation Source:
airbyte.com/quickstart/airbyte-dbt-and-airflow-stack-with-bigquery.txt

Documentation Title:
E-commerce Analytics Stack with Airbyte, dbt, Airflow (ADA) and BigQuery | Airbyte

Documentation Content:
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
2. Create a destination
:
Go to the "Destinations" tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select BigQuery.
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the Service Account Key JSON field, enter the contents of the JSON file. Yes, the full JSON.
Click on Set up destination.
3. Create a connection
:
Go to the "Connections" tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
4. Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery. Here‚Äôs a step-by-step guide to help you set this up:
1. Navigate to the dbt Project Directory
:
Move to the directory containing the dbt configuration:
cd ../../dbt_project
‚Äç
2. Update Connection Details
:
You'll find a <span class="text-style-code">profiles.yml</span> file within the directory. This file contains configurations for dbt to connect with your data platform.
Update this file with your BigQuery connection details. Specifically, you need to update the Service Account JSON file path, the dataset location and your BigQuery project ID.
Provide your BigQuery project ID in the database field of the <span class="text-style-code">/models/ecommerce/sources/faker_sources.yml</span> file.
3. Test the Connection (Optional)
:
You can test the connection to your BigQuery instance using the following command.



Documentation Source:
airbyte.com/tutorials/building-an-e-commerce-data-pipeline-a-hands-on-guide-to-using-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
How to build E-commerce Data Pipeline with Airbyte? | Airbyte

Documentation Content:
Create a source:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
Look fo Faker source connector
Create a Faker source
2. Create a destination:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
Look for BigQuery destination connector
Create a BigQuery destination
3. Create a connection:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
For this project, leave the ‚Äúreplication frequency‚Äù as ‚ÄúManual‚Äù, since we will orchestrate the syncs with Dagster.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
‚Äç
Establish a connector between Faker and BigQuery
4. Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery.
1. Navigate to the dbt Project Directory:
Move to the dbt project directory in your project's file structure.
cd ../../dbt_project
This directory contains all the dbt-related configurations and SQL models.
2. Update Connection Details:
Within this directory, you'll find a <span class="text-style-code">profiles.yml file</span>. This file holds the configuration for dbt to connect to BigQuery.



Documentation Source:
airbyte.com/quickstart/e-commerce-analytics-with-airbyte-dbt-dagster-and-bigquery.txt

Documentation Title:
E-commerce Analytics Stack with Airbyte, dbt, Dagster and BigQuery | Airbyte

Documentation Content:
Setting Up Airbyte Connectors Using the UI
Start by launching the Airbyte UI by going to
http://localhost:8000/
in your browser. Then:
1. Create a source
:
Go to the Sources tab and click on "+ New source".
Search for ‚Äúfaker‚Äù using the search bar and select "Sample Data (Faker)".
Adjust the Count and optional fields as needed for your use case. You can also leave as is.
Click on "Set up source".
2. Create a destination
:
Go to the Destinations tab and click on "+ New destination".
Search for ‚Äúbigquery‚Äù using the search bar and select "BigQuery".
Enter the connection details as needed.
For simplicity, you can use "Standard Inserts" as the loading method.
In the "Service Account Key JSON" field, enter the contents of the JSON file. Yes, the full JSON.
Click on "Set up destination".
3. Create a connection
:
Go to the Connections tab and click on "+ New connection".
Select the source and destination you just created.
Enter the connection details as needed.
Click on "Set up connection".
That‚Äôs it! Your connection is set up and ready to go! üéâ
Setting Up the dbt Project
dbt (data build tool)
allows you to transform your data by writing, documenting, and executing SQL workflows. Setting up the dbt project requires specifying connection details for your data platform, in this case, BigQuery. Here‚Äôs a step-by-step guide to help you set this up:
1. Navigate to the dbt Project Directory
:
Move to the directory containing the dbt configuration:
cd ../../dbt_project
2. Update Connection Details
:
You'll find a <span class="text-style-code">profiles.yml</span> file within the directory. This file contains configurations for dbt to connect with your data platform. Update this file with your BigQuery connection details. Specifically, you need to update the Service Account JSON file path and your BigQuery project ID.
Provide your BigQuery project ID in the database field of the <span class="text-style-code">dbt_project/models/sources/faker_sources.yml</span> file.



Documentation Source:
airbyte.com/tutorials/build-a-github-activity-dashboard-for-your-project.txt

Documentation Title:
Build a GitHub Activity Dashboard for your Project | Airbyte | Airbyte

Documentation Content:
The sync should take a while to complete.
When done, you will see the status change from running to Succeeded. Also, the byte count will be referring to the byte of data Airbyte has pulled from GitHub into your Postgres database.
‚Äç
That wasn‚Äôt a lot of work, was it? You can pat yourself in the back as you just synced data from GitHub to a Postgres database.
Let's move on to connecting that database to Metabase, so we can start creating our dashboard.
Step 2: Connecting the PostgreSQL database to Metabase
Installing Metabase
‚Äç
Metabase is an open source analytic tool that you can get started working with in a couple of ways; using the .jar file, installing it as a Mac app or using a Docker container.
For this tutorial we will be using the Mac app(you can alternatively look up the installation that suits you
here
). To do this, simply run:
If you are on a Mac, you can download the Metabase app from
here
. After download, launch the app and complete registration for an account and you will see the Metabase dashboard:
‚Äç
Setting Up a Postgres Database in Metabase
In order to set up our database, we will click on the cog(settings) icon on the menu bar of the Metabase app and choose the admin option to be taken to the admin view where we can add a database:
‚Äç
Click on the add a database button and you will be presented with a form where you should select PostgreSQL as your database of choice and then fill out the connection parameters which will be the one for the PostgreSQL database we created to hold the data from GitHub
Fill out the details to match the credentials of the PostgreSQL database we created earlier.
‚Äç
‚Äç
Afterwards, hit save when you are done entering the database credentials and your database would have been fully loaded onto Metabase ready for us to start creating our dashboard.
Should you build or buy your data pipelines?
Download our free guide and discover the best approach for your needs, whether it's building your ELT solution in-house or opting for Airbyte Open Source or Airbyte Cloud.



